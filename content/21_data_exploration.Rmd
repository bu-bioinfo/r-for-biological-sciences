---
output: html_document
---

```{r data sci setup, include=FALSE}
library(tidyverse)
```

# Data Science

[Data science](https://en.wikipedia.org/wiki/Data_science) is an enormous and
rapidly growing field that incorporates elements of statistics, computer
science, software engineering, high performance and cloud computing, and big
data management, as well as syntheses with knowledge from other social and
physical science fields to model and predict phenomena captured by data
collected from the "real world". Many books have and will be written on this
subject, and this one does not pretend to even attempt to give this area an
adequate treatment. Like the rest of this book, the topics covered here are
opinionated and presented through the lens of a biological analyst practitioner
with enough high level conceptual details and a few general principles to
hopefully be useful in that context.

## Data Modeling {#ds-model}

The goal of data modeling is to describe a dataset using a relatively small
number of mathematical relationships. Said differently, a model uses some parts
of a dataset to try to accurately predict other parts of the dataset in a way
that is useful to us.

Models are human inventions; they reflect our beliefs about the way the universe
works. The successful model identifies patterns within a dataset that are the
result of causal relationships in the universe that led to the phenomena that
were measured while accounting for noise in the data. However, *the model itself
does not identify or even accurately reflect those causal effects*. In the
made-up Parkinson's Disease example below, we don't have any idea whether Gene 3
is increased due to having disease, or if Parkinson's Disease is more common in
individuals with high gene expression of Gene 3. The model merely detects
patterns and we as scientists are left to interpret those patterns and design
follow up experiments to investigate the nature of those causal relationships
using our prior knowledge of the world.

There are several principles to keep in mind when modeling data:

1. **Data are never wrong.** All data are collected using processes and
devices designed and implemented by humans, who have always have biases and
assumptions. All data measure something about the universe, and so are "true" in
some sense of the world. If what we intended to measure and what we actually
measured were not the same thing, that is due to our errors in collection or
interpretation, not due to the data being wrong. If we approach our dataset with
a particular set of hypotheses and the data don't support those hypotheses, it
is our beliefs of the world that are wrong, not the data.

2. **Not all data are useful.** Just because data isn't wrong, it doesn't mean
it is useful. There may have been systematic errors in the collection of the
data that makes interpreting them difficult. Data collected for one purpose may
not be useful for any other purposes. And sometimes, a dataset collected for a
particular purpose may simply not have the information needed to answer our
questions; if what we measure has no relationship to what we wish to predict,
the data itself is not useful - though the knowledge that what we measured has
no detectable effect on the thing we wish to predict may be very useful!

3. **"All models are wrong, but some are useful."** George Box, the renowned
British statistician, famously asserted this in a 1976 paper to the Journal of
the American Statistical Association. [@Box1976-rd]. By this he meant that every
model we create is a simplification of the system we are seeking to model, which
is by definition not identical to that system. To perfectly model a system, our
model would need to be precisely the system we are modeling, which is no longer
a model but the system itself. Fortunately, even though we know our models are
always wrong to some degree, they may nonetheless be useful because they are not
**too** wrong. Some models may indeed be too wrong, though.

4. **Data do not contain causal information.** "Correlation does not mean
causation." Data are measurements of the results of a process in the universe
that we wish to predict; the data are possibly reflective of that process, but
do not contain any information about the process itself. We cannot infer causal
relationships from a dataset alone. We must construct possible causal models
using our knowledge of the world first, then compare our model to the data and
other models to assess their plausibility.

5. **All data have noise.** The usefulness of a model to describe a dataset is
related to the relative strength of the patterns and noise in the dataset when
viewed through the lens of the model; conceptually, the so-called "signal to
noise ratio" of the data. The fundamental concern of statistics is quantifying
uncertainty (i.e. noise), and separating it from real signal, though different
statistical approaches (e.g. frequentist vs Bayesian) reason about uncertainty
in different ways.

::: {.box .important}
This section pertains primarily to models specified explicitly by humans. There
is another class of models, namely those created by certain machine learning
algorithms like neural networks and deep learning, that *discover models from
data*. These models are fundamentally different than those designed by human
minds, in that they are often accurate and therefore useful, but it can be very
difficult if not impossible to understand how they work. While these are
important types of models that fall under the umbrella of data science, we limit
the content of this chapter to human designed statistical models.
:::

### A Worked Modeling Example

As an example, let's consider a scenario where we wish to assess whether any of
three genes can help us distinguish between patients who have Parkinson's
Disease and those who don't by measuring the relative activity of those genes in
blood samples. We have the following made-up dataset:

```{r data modeling pd, echo=FALSE}
set.seed(1337)
gene_exp <- tibble(
  sample_name = c(str_c("P",1:100), str_c("C",1:100)),
  `Disease Status` = c(rep("Parkinson's",100),rep("Control",100)),
  `Gene 1` = c(rnorm(100,250,10), rnorm(100,255,10)),
  `Gene 2` = c(rnorm(100,520,100), rnorm(100,600,60)),
  `Gene 3` = c(rnorm(100,500,40), rnorm(100,330,40))
)
```

```{r}
gene_exp
```

Our imaginary dataset has 100 Parkinson's and 100 control subjects. For each of
our samples, we have a sample ID, Disease Status of `Parkinson's` or `Control`,
and numeric measurements of each of three genes. Below are [violin
plots](#violin-plot) of our (made-up) data set for these three genes:

```{r data modeling violin, echo=FALSE}
pivot_longer(
  gene_exp,
  c(`Gene 1`, `Gene 2`, `Gene 3`),
  names_to="Gene",
  values_to="Expression"
) %>% ggplot(
    aes(x=`Disease Status`,y=Expression,fill=`Disease Status`)
  ) +
  facet_wrap(vars(Gene)) +
  geom_violin()
```

By inspection, it appears that Gene 1 has no relationship with disease; we may
safely eliminate this gene from further consideration. Gene 2 appears to have a
different profile depending on disease status, where control individuals have
a higher average expression and a lower variance. Unfortunately, despite this
qualitative difference, this gene may not be useful for telling whether someone
has disease or not - the ranges completely overlap. Gene 3 appears to
discriminate between disease and control. There is some overlap in the two
expression distributions, but above a certain expression value these data
suggest a high degree of predictive accuracy may be obtained with this gene.
Measuring this gene may therefore be useful, if the results from this dataset
generalize to all people with Parkinson's Disease.

So far, we have not done any modeling, but instead relied on plotting and our
eyes. A more quantitative question might be: how much higher is Gene 3
expression in Parkinson's Disease than control? Another way of posing this
question is: if I know a patient has Parkinson's Disease, what Gene 3 expression
value do I expect them to have? Written this way, we have turned our question
into a prediction problem: if we only had information that a patient had
Parkinson's Disease, what is the predicted expression value of their Gene 3?

### Data Summarization

Data summarization is similar to modeling in that we are looking to reduce the 
dimensionality of our data. While we are all familiar with the idea of a mean or 
average of a set of numbers, calculating this summarizing value is in effect 
taking many points of data and reducing them to one. The same kind of 
dimensional reduction applies to other measures like median or variance. This 
type of thinking can elevate the idea of a mean or median beyond just a middle 
school math hanger-on.

While summarizing is useful for understanding a large swath of data at a glance, 
this "dimensional reduction" can be useful as we wade through mountains of data. 
A large grid of expression values, tens of columns and thousands of rows, can be 
summarized into a vector of means, one for each row. I can then filter out rows 
that don't meet my criteria. I've effectively reduced a large _two_ dimensional 
problem to a _one_ dimensional problem, a vector of means: one mean per row.  

We don't have the time or need to delve deeply into the number of statistical 
measures of center and variance, but know that there a few fundamental summary 
statistics you'll see every day:

#### Point estimates {-}
Point estimates collapse the data into one singular point, one value. Our two 
favorites will be mean and median.

**Mean**: The arithmetic mean, sum the samples and divide by how many there are. 
Doesn't get better than that. Vulnerable to skewing by outliers.  
```{r fig.align="center"}
data <- tibble(data = rnorm(1000))
ggplot(data, aes(x = data)) + 
  geom_histogram(fill = "#56CBF9", color = "grey", bins = 30) +
  geom_vline(xintercept = mean(data$data)) +
  theme_bw() + ggtitle("Mean example, no outliers") + xlab("") + ylab("")
```
```{r fig.align="center"}
data <- tibble(data = c(rnorm(800), rep(5, 200))) # oops I add some outliers :^)
ggplot(data, aes(x = data)) + 
  geom_histogram(fill = "#7FBEEB", color = "grey", bins = 30) +
  geom_vline(xintercept = mean(data$data)) +
  theme_bw() + ggtitle("Mean example, big outliers") + xlab("") + ylab("")
```

**Median**: Put the data in order, take the value that's right in the middle. 
More resistant to outliers.
```{r fig.align="center"}
data <- tibble(data = c(rnorm(1000)))
ggplot(data, aes(x = data)) + 
  geom_histogram(fill = "#AFBED1", color = "white", bins = 30) +
  geom_vline(xintercept = median(data$data)) +
  theme_bw() + ggtitle("Median example") + xlab("") + ylab("")
```

#### Dispersion {-}
Measures the spread of the data, typically around its perceived center (a mean). 
Often related to the distribution of the data.

**Standard deviation**: A measure of how close values are to the mean. Bigger 
standard deviations mean data is more spread out.

```{r fig.align="center"}
data <- tibble(data = c(rnorm(1000, sd=1.75)))
ggplot(data, aes(x = data)) + 
  geom_histogram(fill = "#EAC5D8", color = "white", bins = 30) +
  geom_vline(xintercept = c(-2, -1, 0, 1, 2) * sd(data$data)) +
  theme_bw() + xlab("") + ylab("") + xlim(c(-6, 6)) +
  ggtitle("Standard deviations aplenty", paste("SD:", sd(data$data))) 
```

**Variance**: 
Similar to SD (it's the square of SD), variance measures how far a random value 
is from the mean.
```{r fig.align="center"}
data <- tibble(data = c(rnorm(1000, sd=0.5)))
ggplot(data, aes(x = data)) + 
  geom_histogram(fill = "#DBD8F0", color = "white", bins = 30) +
  geom_vline(xintercept = mean(data$data)) +
  theme_bw() + xlab("") + ylab("") + xlim(c(-6, 6)) +
  ggtitle("Same mean as SD plot, but different variance", 
          paste("Variance:", sd(data$data))) 
```


#### Distributions {-}
Finally, distributions are fun names for shapes of data. Some models can use 
distributions to predict values, while others change based on what distribution 
the data falls under. R has a number of built-in functions to create and test 
these distributions:
```{r fig.align="center"}
ggplot(tibble(data = rnorm(5000)), aes(x = data)) + 
  geom_histogram(fill = "#D0FCB3", bins = 50, color = "gray") + theme_bw() +
  ggtitle("Normal distribution", "rnorm(n = 1000)") + xlab("") + ylab("")
```
```{r fig.align="center"}
ggplot(tibble(data = runif(5000)), aes(x = data)) + 
  geom_histogram(fill = "#271F30", bins = 50, color = "white") + theme_bw() +
  ggtitle("Uniform distribution", "runif(n = 1000)") + xlab("") + ylab("")
```
```{r fig.align="center"}
ggplot(tibble(data = rlogis(5000)), aes(x = data)) + 
  geom_histogram(fill = "#9BC59D", bins = 50, color = "black") + theme_bw() +
  ggtitle("Logistic distribution", "rlogis(n = 1000)") + 
  xlab("") + ylab("")
```
```{r fig.align="center"}
ggplot(tibble(data = rexp(5000, rate = 1)), aes(x = data)) + 
  geom_histogram(fill = "#6C5A49", bins = 50, color = "white") + theme_bw() +
  ggtitle("Exponential distribution", "rexp(n = 1000, rate = 1)") + 
  xlab("") + ylab("")
```

### Linear Models .

What is a linear model? Conceptually, how do they work? How do you interpret the
results of a linear model? How do you implement a linear model in R?

## Statistical Distributions & Tests .

### Statistical Distributions .

What is a distribution? Why are they important? In brief terms, how are
distributions defined mathematically? What are some common distributions, and
when are they used? What do different distributions look like when plotted? How
do we work with distributions in R (e.g. dnorm, pnorm, qnorm, rnorm)?

### Statistical Tests .

What is a statistical test, and when is it appropriate to run one? How do we
know which tests are appropriate in a given situation? What is the difference
between a parametric and non-parametric test? What are some common tests (e.g.
t-test, Chi-sq, hypergeometric, etc), and how do we run them in R?

### p-values .

What is a p-value? What is the relationship between a p-value and a distribution?
What does a p-value look like when plotted with a distribution? How do we
interpret p-values? How do we compute a p-value using a distribution and a
statistic using R? (Should we mention critical values?)

### Multiple Hypothesis Testing .

What is multiply hypothesis testing adjustment? Why is it important? What are
some common adjustment methods (Bonferroni (FWER) and Benjamini-Hochberg (FDR))?
How do we interpret adjusted p-values (depends on the adjustment method)? How
do we compute adjusted p-values in R?

### Statistical power .

Conceptually, what is statistical power, and what does it mean? Why is it
important? What is the relationship between a dataset, an analysis, and power?
What aspects of an analysis influence the statistical power of a test? (I don't
think it's reasonable to ask students to perform power calculations, just to be
aware that power is a thing and generally what it is).

## Clustering .

What is clustering? What is the goal of clustering? How does clustering relate
to data modeling (e.g. clustering is usually hypothesis-free)? How is clustering
useful (i.e. what can we do with different clusters)? What are some common
clustering methods, and how do we implement and visualize the results in R?

## Network Analysis .

What is a network? What is network analysis? What are some example network
analysis applications in biology and bioinformatics (there is a full ksection on
[Biological Networks] in the bio chapter, these are just illustrative examples)?
How do we represent networks in R, and how do we analyze them? ([Network
visualization] is covered in the data viz chapter, might be helpful to write
these two sections together)
