<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>7 Data Science | BF591 - R for Biological Sciences</title>
<meta name="generator" content="bookdown 0.40 with bs4_book()">
<meta property="og:title" content="7 Data Science | BF591 - R for Biological Sciences">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="7 Data Science | BF591 - R for Biological Sciences">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Data science is an enormous and rapidly growing field that incorporates elements of statistics, computer science, software engineering, high performance and cloud computing, and big data...">
<meta property="og:description" content="Data science is an enormous and rapidly growing field that incorporates elements of statistics, computer science, software engineering, high performance and cloud computing, and big data...">
<meta name="twitter:description" content="Data science is an enormous and rapidly growing field that incorporates elements of statistics, computer science, software engineering, high performance and cloud computing, and big data...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">BF591 - R for Biological Sciences</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">R for Biological Sciences</a></li>
<li><a class="" href="detailed-class-schedule.html"><span class="header-section-number">1</span> Detailed Class Schedule</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="data-bio.html"><span class="header-section-number">3</span> Data in Biology</a></li>
<li><a class="" href="preliminaries.html"><span class="header-section-number">4</span> Preliminaries</a></li>
<li><a class="" href="prog-basics.html"><span class="header-section-number">5</span> R Programming</a></li>
<li><a class="" href="data-wrangling.html"><span class="header-section-number">6</span> Data Wrangling</a></li>
<li><a class="active" href="data-science.html"><span class="header-section-number">7</span> Data Science</a></li>
<li><a class="" href="data-visualization.html"><span class="header-section-number">8</span> Data Visualization</a></li>
<li><a class="" href="biology-bioinformatics.html"><span class="header-section-number">9</span> Biology &amp; Bioinformatics</a></li>
<li><a class="" href="engineering.html"><span class="header-section-number">10</span> EngineeRing</a></li>
<li><a class="" href="rshiny.html"><span class="header-section-number">11</span> RShiny</a></li>
<li><a class="" href="communicating-with-r.html"><span class="header-section-number">12</span> Communicating with R</a></li>
<li><a class="" href="contribution-guide.html"><span class="header-section-number">13</span> Contribution Guide</a></li>
<li class="book-part">Assignments</li>
<li><a class="" href="starting-an-assignment.html">Starting an Assignment</a></li>
<li><a class="" href="assignment-overview.html">Assignment Overview</a></li>
<li><a class="" href="assignment-0.html">Assignment 0</a></li>
<li><a class="" href="base-r.html">Base R</a></li>
<li><a class="" href="tidyverse-basics.html">Tidyverse Basics</a></li>
<li><a class="" href="bioinformatics-basics.html">Bioinformatics Basics</a></li>
<li><a class="" href="data-science-basics.html">Data Science Basics</a></li>
<li><a class="" href="counts-analysis.html">Counts Analysis</a></li>
<li><a class="" href="differential-expression-part-1.html">Differential Expression Part 1</a></li>
<li><a class="" href="differential-expression-part-2.html">Differential Expression Part 2</a></li>
<li><a class="" href="rshiny-basics.html">RShiny Basics</a></li>
<li><a class="" href="final-project.html">Final Project</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="bibliography.html"><span class="header-section-number">A</span> Bibliography</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="data-science" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Data Science<a class="anchor" aria-label="anchor" href="#data-science"><i class="fas fa-link"></i></a>
</h1>
<p><a href="https://en.wikipedia.org/wiki/Data_science">Data science</a> is an enormous and
rapidly growing field that incorporates elements of statistics, computer
science, software engineering, high performance and cloud computing, and big
data management, as well as syntheses with knowledge from other social and
physical science fields to model and predict phenomena captured by data
collected from the “real world”. Many books have and will be written on this
subject, and this one does not pretend to even attempt to give this area an
adequate treatment. Like the rest of this book, the topics covered here are
opinionated and presented through the lens of a biological analyst practitioner
with enough high level conceptual details and a few general principles to
hopefully be useful in that context.</p>

<div id="data-modeling" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Data Modeling<a class="anchor" aria-label="anchor" href="#data-modeling"><i class="fas fa-link"></i></a>
</h2>
<p>The goal of data modeling is to describe a dataset using a relatively small
number of mathematical relationships. Said differently, a model uses some parts
of a dataset to try to accurately predict other parts of the dataset in a way
that is useful to us.</p>
<p>Models are human inventions; they reflect our beliefs about the way the universe
works. The successful model identifies patterns within a dataset that are the
result of causal relationships in the universe that led to the phenomena that
were measured while accounting for noise in the data. However, <em>the model itself
does not identify or even accurately reflect those causal effects</em>. The model
merely summarizes patterns and we as scientists are left to interpret those
patterns and design follow up experiments to investigate the nature of those
causal relationships using our prior knowledge of the world.</p>
<p>There are several principles to keep in mind when modeling data:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Data are never wrong.</strong> All data are collected using processes and
devices designed and implemented by humans, who always have biases and make
assumptions. All data measure something about the universe, and so are “true” in
some sense of the word. If what we intended to measure and what we actually
measured were not the same thing, that is due to our errors in collection or
interpretation, not due to the data being wrong. If we approach our dataset with
a particular set of hypotheses and the data don’t support those hypotheses, it
is our beliefs of the world and our understanding of the dataset that are wrong,
not the data itself.</p></li>
<li><p><strong>Not all data are useful.</strong> Just because data isn’t wrong, it doesn’t mean
it is useful. There may have been systematic errors in the collection of the
data that makes interpreting them difficult. Data collected for one purpose may
not be useful for any other purposes. And sometimes, a dataset collected for a
particular purpose may simply not have the information needed to answer our
questions; if what we measure has no relationship to what we wish to predict,
the data itself is not useful - though the knowledge that what we measured has
no detectable effect on the thing we wish to predict may be very useful!</p></li>
<li><p><strong>“All models are wrong, but some are useful.”</strong> George Box, the renowned
British statistician, famously asserted this in a 1976 paper to the Journal of
the American Statistical Association. <span class="citation">(<a href="bibliography.html#ref-Box1976-rd">Box 1976</a>)</span>. By this he meant that every
model we create is a simplification of the system we are seeking to model, which
is by definition not identical to that system. To perfectly model a system, our
model would need to be precisely the system we are modeling, which is no longer
a model but the system itself. Fortunately, even though we know our models are
always wrong to some degree, they may nonetheless be useful because they are not
<strong>too</strong> wrong. Some models may indeed be too wrong, though.</p></li>
<li><p><strong>Data do not contain causal information.</strong> “Correlation does not mean
causation.” Data are measurements of the results of a process in the universe
that we wish to understand; the data are possibly reflective of that process,
but do not contain any information about the process itself. We cannot infer
causal relationships from a dataset alone. We must construct possible causal
models using our knowledge of the world first, then apply our data to our model
and other alternative models to compare their relative plausibility.</p></li>
<li><p><strong>All data have noise.</strong> The usefulness of a model to describe a dataset is
related to the relative strength of the patterns and noise in the dataset when
viewed through the lens of the model; conceptually, the so-called “signal to
noise ratio” of the data. The fundamental concern of statistics is quantifying
uncertainty (i.e. noise), and separating it from real signal, though different
statistical approaches (e.g. frequentist vs Bayesian) reason about uncertainty
in different ways.</p></li>
</ol>
<p>Modeling begins (or should begin) with posing one or more <strong>scientific models</strong>
of the process or phenomenon we wish to understand. The scientific model is
conceptual; it reflects our belief of the universe and proposes a causal
explanation for the phenomenon. We then decide how to map that scientific model
onto a <strong>statistical model</strong>, which is a mechanical procedure that quantifies
how well our scientific model explains a dataset. <em>The scientific model and
statistical model are related but independent choices we make.</em> There may be
many valid statistical models that represent a given scientific model. However,
sometimes in practice we lack sufficient knowledge about the process to propose
scientific models first, requiring data exploration and summarization first to
suggest reasonable starting points.</p>
<div class="box important">
<p>This section pertains primarily to models specified explicitly by humans. There
is another class of models, namely those created by certain machine learning
algorithms like neural networks and deep learning, that <em>discover models from
data</em>. These models are fundamentally different than those designed by human
minds, in that they are often accurate and therefore useful, but it can be very
difficult if not impossible to understand how they work. While these are
important types of models that fall under the umbrella of data science, we limit
the content of this chapter to human designed statistical models.</p>
</div>
<div id="a-worked-modeling-example" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> A Worked Modeling Example<a class="anchor" aria-label="anchor" href="#a-worked-modeling-example"><i class="fas fa-link"></i></a>
</h3>
<p>As an example, let’s consider a scenario where we wish to assess whether any of
three genes can help us distinguish between patients who have Parkinson’s
Disease and those who don’t by measuring the relative activity of those genes in
blood samples. We have the following made-up dataset:</p>
<div class="sourceCode" id="cb175"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gene_exp</span></span></code></pre></div>
<pre><code>## # A tibble: 200 × 5
##    sample_name `Disease Status` `Gene 1` `Gene 2` `Gene 3`
##    &lt;chr&gt;       &lt;fct&gt;               &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1 P1          Parkinson's          257.     636.     504.
##  2 P2          Parkinson's          241.     556.     484.
##  3 P3          Parkinson's          252.     426.     476.
##  4 P4          Parkinson's          271.     405.     458.
##  5 P5          Parkinson's          248.     482.     520.
##  6 P6          Parkinson's          275.     521.     460.
##  7 P7          Parkinson's          264.     415.     568.
##  8 P8          Parkinson's          276.     450.     495.
##  9 P9          Parkinson's          274.     490.     496.
## 10 P10         Parkinson's          251.     584.     573.
## # ℹ 190 more rows</code></pre>
<p>Our imaginary dataset has 100 Parkinson’s and 100 control subjects. For each of
our samples, we have a sample ID, Disease Status of <code>Parkinson's</code> or <code>Control</code>,
and numeric measurements of each of three genes. Below are <a href="data-visualization.html#violin-plot">violin
plots</a> of our (made-up) data set for these three genes:</p>
<div class="inline-figure"><img src="main_files/data%20modeling%20violin-1.png" width="672"></div>
<p>By inspection, it appears that Gene 1 has no relationship with disease; we may
safely eliminate this gene from further consideration. Gene 2 appears to have a
different profile depending on disease status, where control individuals have
a higher average expression and a lower variance. Unfortunately, despite this
qualitative difference, this gene may not be useful for telling whether someone
has disease or not - the ranges completely overlap. Gene 3 appears to
discriminate between disease and control. There is some overlap in the two
expression distributions, but above a certain expression value these data
suggest a high degree of predictive accuracy may be obtained with this gene.
Measuring this gene may therefore be useful, if the results from this dataset
generalize to all people with Parkinson’s Disease.</p>
<p>So far, we have not done any modeling, but instead relied on plotting and our
eyes. A more quantitative question might be: how much higher is Gene 3
expression in Parkinson’s Disease than control? Another way of posing this
question is: if I know a patient has Parkinson’s Disease, what Gene 3 expression
value do I expect them to have? Written this way, we have turned our question
into a prediction problem: if we only had information that a patient had
Parkinson’s Disease, what is the predicted expression value of their Gene 3?</p>
<p>Another way to pose this prediction question is in the opposite (and arguably
more useful) direction: if all we knew about a person was their Gene 3 gene
expression, how likely is it that the person has Parkinson’s Disease? If this
gene expression is predictive enough of a person’s disease status, it may be a
viable <a href="https://en.wikipedia.org/wiki/Biomarker">biomarker</a> of disease and thus
might be useful in a clinical setting, for example when identifying
presymptomatic individuals or assessing the efficacy of a pharmacological
treatment.</p>
<p>Although it may seems obvious, before beginning to model a dataset, we must
start by posing the <strong>scientific question</strong> as concisely as possible, as we have
done above. These questions will help us identify which modeling techniques are
appropriate and help us ensure we interpret our results correctly.</p>
<p>We will use this example dataset throughout this chapter to illustrate some key
concepts.</p>
</div>
<div id="data-summarization" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> Data Summarization<a class="anchor" aria-label="anchor" href="#data-summarization"><i class="fas fa-link"></i></a>
</h3>
<p>Broadly speaking, <em>data summarization</em> is the process of finding a
lower-dimensional representation of a larger dataset. There are many ways to
summarize a set of data; each approach will emphasize different aspects of the
dataset, and have varying degrees of accuracy. Consider the gene expression of
Gene 1 for all individuals in our example above, plotted as a distribution with
a <a href="data-visualization.html#histogram">histogram</a>:</p>
<div class="sourceCode" id="cb177"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">`Gene 1`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>bins<span class="op">=</span><span class="fl">30</span>,fill<span class="op">=</span><span class="st">"#a93c13"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/data%20sci%20summ%20hist-1.png" width="672"></div>
<div id="point-estimates" class="section level4" number="7.1.2.1">
<h4>
<span class="header-section-number">7.1.2.1</span> Point Estimates<a class="anchor" aria-label="anchor" href="#point-estimates"><i class="fas fa-link"></i></a>
</h4>
<p>The data are concentrated around the value 250, and become less common for
larger and smaller values. Since the extents to the left and right of the middle
of the distribution appear to be equally distant, perhaps the arithmetic mean
is a good way to identify the middle of the distribution:</p>
<div class="sourceCode" id="cb178"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">`Gene 1`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>bins<span class="op">=</span><span class="fl">30</span>,fill<span class="op">=</span><span class="st">"#a93c13"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">gene_exp</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/data%20sci%20summ%20hist2-1.png" width="672"></div>
<p>By eye, the mean does seem to correspond well to the value that is among the
most frequent, and successfully captures an important aspect of the data: its
<em>central tendency</em>. Summaries that compute a single number are called <em>point
estimates</em>. Point estimates collapse the data into one singular point, one
value.</p>
<div class="box">
<p>The arithmetic mean is just one measure of central tendency, computed by taking
the sum of all the values and dividing by the number of values. The mean may be
a good point estimate of the central tendency of a dataset, but it is sensitive
to outlier samples. Consider the following examples:</p>
<div class="sourceCode" id="cb179"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="va">well_behaved_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data_w_outliers</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">800</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">200</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># oops I add some outliers :^)</span></span>
<span></span>
<span><span class="va">g_no_outlier</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">well_behaved_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#56CBF9"</span>, color <span class="op">=</span> <span class="st">"grey"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">well_behaved_data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Mean example, no outliers"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_outlier</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">data_w_outliers</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#7FBEEB"</span>, color <span class="op">=</span> <span class="st">"grey"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data_w_outliers</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Mean example, big outliers"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_no_outlier</span> <span class="op">|</span> <span class="va">g_outlier</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-45-1.png" width="672" style="display: block; margin: auto;"></div>
<p>The median is another measure of central tendency, which is found by identifying
the value that divides the samples into equal halves when sorted from smallest
to largest. The median is more robust in the presence of outliers.</p>
<div class="sourceCode" id="cb180"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g_no_outlier</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">well_behaved_data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#AFBED1"</span>, color <span class="op">=</span> <span class="st">"grey"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">well_behaved_data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Median example"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_outlier</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">data_w_outliers</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#7FBEEB"</span>, color <span class="op">=</span> <span class="st">"grey"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">data_w_outliers</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Median example, big outliers"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_no_outlier</span> <span class="op">|</span> <span class="va">g_outlier</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-46-1.png" width="672" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="dispersion" class="section level4" number="7.1.2.2">
<h4>
<span class="header-section-number">7.1.2.2</span> Dispersion<a class="anchor" aria-label="anchor" href="#dispersion"><i class="fas fa-link"></i></a>
</h4>
<p>Central tendencies are important aspects of the data but don’t describe what the
data do for values outside this point estimate of central tendency; in other
words, we have not expressed the spread, or <em>dispersion</em> of the data.</p>
<p>We decide that perhaps computing the <a href="https://en.wikipedia.org/wiki/Standard_deviation">standard
deviation</a> of the data may
characterize the spread well, since it appears to be symmetric around the mean.
We can layer this information on the plot as well to inspect it:</p>
<div class="sourceCode" id="cb181"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g1_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">gene_exp</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="va">g1_sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">gene_exp</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">`Gene 1`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>bins<span class="op">=</span><span class="fl">30</span>,fill<span class="op">=</span><span class="st">"#a93c13"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept<span class="op">=</span><span class="va">g1_mean</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_segment</span><span class="op">(</span>x<span class="op">=</span><span class="va">g1_mean</span><span class="op">-</span><span class="va">g1_sd</span>, y<span class="op">=</span><span class="fl">10</span>, xend<span class="op">=</span><span class="va">g1_mean</span><span class="op">+</span><span class="va">g1_sd</span>, yend<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/data%20sci%20summ%20sd-1.png" width="672"></div>
<p>The width of the horizontal line is proportional to the mean +/- one standard
deviation around the mean, and has been placed arbitrarily on the y axis at <code>y = 10</code> to show how this range covers the data in the histogram. The +/- 1 standard
deviation around the mean visually describes the spread of the data reasonably
well.</p>
<div class="box">
<p>Measures the spread of the data, typically around its perceived center (a mean).
Often related to the distribution of the data.</p>
<p><strong>Standard deviation</strong>: A measure of how close values are to the mean. Bigger
standard deviations mean data is more spread out.</p>
<div class="sourceCode" id="cb182"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, sd<span class="op">=</span><span class="fl">1.75</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#EAC5D8"</span>, color <span class="op">=</span> <span class="st">"white"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">xlim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">6</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Standard deviations aplenty"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"SD:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/taylor%20sd-1.png" width="672" style="display: block; margin: auto;"></div>
<p><strong>Variance</strong>:
Similar to SD (it’s the square of SD), variance measures how far a random value
is from the mean.</p>
<div class="sourceCode" id="cb183"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, sd<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">data</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#DBD8F0"</span>, color <span class="op">=</span> <span class="st">"white"</span>, bins <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">xlim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">6</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Same mean as SD plot, but different variance"</span>,</span>
<span>          <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Variance:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">data</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/taylor%20var-1.png" width="672" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="distributions" class="section level4" number="7.1.2.3">
<h4>
<span class="header-section-number">7.1.2.3</span> Distributions<a class="anchor" aria-label="anchor" href="#distributions"><i class="fas fa-link"></i></a>
</h4>
<p>With these two pieces of knowledge - the mean accurately describes the center of
the data and the standard deviation describes the spread - we now recognize that
these data may be <a href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a>, and therefore
we can potentially describe the dataset mathematically. We decide to visually
inspect this possibility by layering a normal distribution on top of our data
using
<a href="https://ggplot2.tidyverse.org/reference/geom_function.html"><code>stat_function</code></a>:</p>
<div class="sourceCode" id="cb184"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g1_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">gene_exp</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="va">g1_sd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">gene_exp</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">`Gene 1`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span></span>
<span>    <span class="fu">aes</span><span class="op">(</span>y<span class="op">=</span><span class="fu">after_stat</span><span class="op">(</span><span class="va">density</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    bins<span class="op">=</span><span class="fl">30</span>,</span>
<span>    fill<span class="op">=</span><span class="st">"#a93c13"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">stat_function</span><span class="op">(</span>fun<span class="op">=</span><span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean<span class="op">=</span><span class="va">g1_mean</span>, sd<span class="op">=</span><span class="va">g1_sd</span><span class="op">)</span>, size<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-47-1.png" width="672"></div>
<p>Note the histogram bars are scaled with
<code>aes(y=[after_stat](https://ggplot2.tidyverse.org/reference/aes_eval.html)(density))</code>
to the density of values in each bin to make all the bar heights sum to 1 so
that the y scale matches that of a normal distribution.</p>
<p>We have now created our first model: we chose to express the dataset as a normal
distribution parameterized by the mean and standard deviation and standard
deviation of the data. Using the values of 254 and 11
as our mean and standard deviation, respectively, we can express our model
mathematically as follows:</p>
<p><span class="math display">\[
Gene\;1 \sim \mathcal{N}(254, 11)
\]</span></p>
<p>Here the <span class="math inline">\(\sim\)</span> symbol means “distributed as” and the <span class="math inline">\(\mathcal{N}(\mu,\sigma)\)</span>
represents a normal distribution with mean of <span class="math inline">\(\mu\)</span> and standard deviation of
<span class="math inline">\(\sigma\)</span>. This is mathematical formulation means the same thing as saying we are
modeling Gene 1 expression as a normal distribution with mean of 254 and
standard deviation of 11. Without any additional information about a new sample,
we would expect the expression of that gene to be 254, although it may vary from
this value.</p>
<div class="box">
<p>The normal distribution is the most common distribution observed in nature, but
it is hardly the only one. We could have proposed other distributions to instead
summarize our data:</p>
<div class="sourceCode" id="cb185"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g_norm</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">5000</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#D0FCB3"</span>, bins <span class="op">=</span> <span class="fl">50</span>, color <span class="op">=</span> <span class="st">"gray"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Normal distribution"</span>, <span class="st">"rnorm(n = 1000)"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_unif</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">5000</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#271F30"</span>, bins <span class="op">=</span> <span class="fl">50</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Uniform distribution"</span>, <span class="st">"runif(n = 1000)"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_logistic</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">rlogis</a></span><span class="op">(</span><span class="fl">5000</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#9BC59D"</span>, bins <span class="op">=</span> <span class="fl">50</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Logistic distribution"</span>, <span class="st">"rlogis(n = 1000)"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">g_exp</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">5000</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_histogram</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"#6C5A49"</span>, bins <span class="op">=</span> <span class="fl">50</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Exponential distribution"</span>, <span class="st">"rexp(n = 1000, rate = 1)"</span><span class="op">)</span></span>
<span></span>
<span><span class="op">(</span><span class="va">g_norm</span> <span class="op">|</span> <span class="va">g_unif</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">g_logistic</span> <span class="op">|</span> <span class="va">g_exp</span><span class="op">)</span></span></code></pre></div>
<p><img src="main_files/unnamed-chunk-48-1.png" width="672" style="display: block; margin: auto;">
In addition to the normal distribution, we have also plotted samples drawn from
a <a href="ihttps://en.wikipedia.org/wiki/Continuous_uniform_distribution">continuous uniform
distribution</a>
between 0 and 1, a <a href="https://en.wikipedia.org/wiki/Logistic_distribution">logistic
distribution</a> which is
similar to the normal distribution but has heavier “tails”, and an <a href="https://en.wikipedia.org/wiki/Exponential_distribution">exponential
distribution</a>.
There are many more distributions than these, and many of them were discovered
to arise in nature and encode different types of processes and relationships.</p>
</div>
<p>A few notes on our data modeling example before we move on:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Our model choice was totally subjective.</strong> We looked at the data and
decided that a normal distribution was a reasonable choice. There were many
other choices we could have made, and all of them would be equally valid, though
they may not all describe the data equally well.</p></li>
<li><p><strong>We can’t know if this is the “correct” model for the data.</strong> By eye, it
appears to be a reasonably accurate summary. However, there is no such thing as
a correct model; some models are simply better at describing the data than
others. Recall that all models are wrong, and some models are useful. Our model
may be useful, but it is definitely wrong to some extent.</p></li>
<li><p><strong>We don’t know how well our model describes the data yet.</strong> So far we’ve
only used our eyes to choose our model which might be a good starting point
considering our data are so simple, but we have not yet quantified how well our
model describes the data, or compared it to alternative models to see which is
better. This will be discussed briefly in a later section.</p></li>
</ol>
</div>
</div>
<div id="linear-models" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> Linear Models<a class="anchor" aria-label="anchor" href="#linear-models"><i class="fas fa-link"></i></a>
</h3>
<p>Our choice of a normal distribution to model our Gene 1 gene expression was only
<em>descriptive</em>; it was a low-dimensional summary of our dataset. However, it was
not very <em>informative</em>; it doesn’t tell us anything useful about Gene 1
expression with respect to our scientific question of distinguishing between
Parkinson’s Disease and Control individuals. To do that, we will need to find a
model that can make <em>predictions</em> that we may find useful if we receive new
data. To do that, we will introduce a new type of model: the linear model.</p>
<p>A linear model is any statistical model that relates one outcome variable as a
linear combination (i.e. sum) of one or more explanatory variables. This may be
expressed mathematically as follows:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 \phi_1 ( X_{i1} ) + \beta_2 \phi_2 ( X_{i2} ) + \ldots + \beta_p \phi_p ( X_{ip} ) + \epsilon_i
\]</span></p>
<p>Above, <span class="math inline">\(Y_i\)</span> is some outcome or response variable we wish to model, <span class="math inline">\(X_{ij}\)</span> is
our explanatory or predictor variable <span class="math inline">\(j\)</span> for observatoin <span class="math inline">\(i\)</span>, and <span class="math inline">\(\beta_j\)</span> are
coefficients estimated to minimize the difference between the predicted outcome
<span class="math inline">\(\hat{Y_i}\)</span> and the observed <span class="math inline">\(Y_i\)</span> over all observations. <span class="math inline">\(\phi_j\)</span> is a possibly
non-linear transformation of the explanatory variable <span class="math inline">\(X_ij\)</span>; note these
functions may be non-linear so long as the predicted outcome is modeled as a
linear combination of the transformed variables. The rest of this section is
dedicated to a worked example of a linear model for gene expression data.</p>
<p>Let us begin with a <a href="data-visualization.html#beeswarm-plot">beeswarm plot</a> plot of Gene 3:</p>
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/eclarke/ggbeeswarm">ggbeeswarm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Disease Status`</span>, y<span class="op">=</span><span class="va">`Gene 3`</span>, color<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/lin%20model%20gene%203%20violin-1.png" width="672"></div>
<p>The expression values within each disease status look like they might be
normally distributed just like Gene 1, so let’s summarize each group with the
arithmetic mean and standard deviation as before, and instead plot both
distributions as histograms:</p>
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">exp_summ</span> <span class="op">&lt;-</span> <span class="fu">pivot_longer</span><span class="op">(</span></span>
<span>  <span class="va">gene_exp</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">`Gene 3`</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">`Disease Status`</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>mean<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">value</span><span class="op">)</span>,sd<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">value</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pd_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">exp_summ</span>, <span class="va">`Disease Status`</span> <span class="op">==</span> <span class="st">"Parkinson's"</span><span class="op">)</span><span class="op">$</span><span class="va">mean</span></span>
<span><span class="va">c_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">exp_summ</span>, <span class="va">`Disease Status`</span> <span class="op">==</span> <span class="st">"Control"</span><span class="op">)</span><span class="op">$</span><span class="va">mean</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Gene 3`</span>, fill<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">20</span>, alpha<span class="op">=</span><span class="fl">0.6</span>,position<span class="op">=</span><span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x<span class="op">=</span><span class="va">c_mean</span>, xend<span class="op">=</span><span class="va">pd_mean</span>, y<span class="op">=</span><span class="fl">20</span>, yend<span class="op">=</span><span class="fl">20</span>, arrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span>ends<span class="op">=</span><span class="st">"both"</span>, angle<span class="op">=</span><span class="fl">90</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">c_mean</span>,<span class="va">pd_mean</span><span class="op">)</span><span class="op">)</span>, y<span class="op">=</span><span class="fl">21</span>, hjust<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"How different?"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-49-1.png" width="672"></div>
<p>We can make a point estimate of this difference by simply subtracting the means:</p>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pd_mean</span> <span class="op">-</span> <span class="va">c_mean</span></span></code></pre></div>
<pre><code>## [1] 164.0942</code></pre>
<p>In other words, this point estimate suggests that on average Parkinson’s
patients have 164.1 greater expression than Controls. We can
plot this relationship relatively simply:</p>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Disease Status`</span>, y<span class="op">=</span><span class="va">`Gene 3`</span>, color<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x<span class="op">=</span><span class="fl">0</span>, xend<span class="op">=</span><span class="fl">3</span>, y<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">c_mean</span><span class="op">-</span><span class="va">pd_mean</span>, yend<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">pd_mean</span><span class="op">-</span><span class="va">c_mean</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/lin%20model%20gene%203%20fit-1.png" width="672"></div>
<p>However, this point estimate tells us nothing about how confident we are about
the difference. We can do this by using an <a href="https://en.wikipedia.org/wiki/Least_squares">linear
regression</a> by modeling Gene 3 as a
function of disease status:</p>
<div class="sourceCode" id="cb191"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">`Gene 3`</span> <span class="op">~</span> <span class="va">`Disease Status`</span>, data<span class="op">=</span><span class="va">gene_exp</span><span class="op">)</span></span>
<span><span class="va">fit</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = `Gene 3` ~ `Disease Status`, data = gene_exp)
## 
## Coefficients:
##                 (Intercept)  `Disease Status`Parkinson's  
##                       334.6                        164.1</code></pre>
<p>The coefficient associated with having the disease status of Parkinson’s disease
is almost exactly equal to our difference in means. We also note that the
coefficient labeled <code>(Intercept)</code> is nearly equal to the mean of our control
samples (334.6). Under the hood, this simple linear model did the
same calculation we did by subtracting the means of each group but estimated the
means using all the data at once, instead of point estimates. Another advantage
of using <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> over the point estimate method is the model can estimate how
confident the model was that the difference in mean between Parkinson’s and
controls subjects. Let’s print some more information about the model than
before:</p>
<div class="sourceCode" id="cb193"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = `Gene 3` ~ `Disease Status`, data = gene_exp)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -124.303  -25.758   -2.434   30.518  119.348 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                  334.578      4.414   75.80   &lt;2e-16 ***
## `Disease Status`Parkinson's  164.094      6.243   26.29   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 44.14 on 198 degrees of freedom
## Multiple R-squared:  0.7773, Adjusted R-squared:  0.7761 
## F-statistic:   691 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We again see our coefficient estimates for the intercept (i.e. mean control
expression) and our increase in Parkinson’s, but also a number of other terms,
in particular <code>Pr(&gt;|t|)</code> and <code>Multiple R-squared</code>. The former is the
<a href="data-science.html#p-values">p-value</a> associated with each of the coefficient estimates, both of
which are very small, indicating to us that the model was very confident of the
estimated values. The latter, multiple R-squared or <span class="math inline">\(R^2\)</span>, describes how much of
the variance in the data was explained by the model it found as a fraction
between 0 and 1. This model explains 77.7% of the variance of the data, which is
substantial. The <span class="math inline">\(R^2\)</span> value also has an associated p-value, which is also very
small. Overall, these statistics suggest this model fits the data very well.</p>
<p>We can plot the results of a linear model for each of our genes relatively
easily:</p>
<div class="sourceCode" id="cb195"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pd_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Parkinson's"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="va">c_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Control"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 1`</span><span class="op">)</span></span>
<span><span class="va">g1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Disease Status`</span>, y<span class="op">=</span><span class="va">`Gene 1`</span>, color<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x<span class="op">=</span><span class="fl">0</span>, xend<span class="op">=</span><span class="fl">3</span>, y<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">c_mean</span><span class="op">-</span><span class="va">pd_mean</span>, yend<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">pd_mean</span><span class="op">-</span><span class="va">c_mean</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pd_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Parkinson's"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 2`</span><span class="op">)</span></span>
<span><span class="va">c_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Control"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 2`</span><span class="op">)</span></span>
<span><span class="va">g2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Disease Status`</span>, y<span class="op">=</span><span class="va">`Gene 2`</span>, color<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x<span class="op">=</span><span class="fl">0</span>, xend<span class="op">=</span><span class="fl">3</span>, y<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">c_mean</span><span class="op">-</span><span class="va">pd_mean</span>, yend<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">pd_mean</span><span class="op">-</span><span class="va">c_mean</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pd_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Parkinson's"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 3`</span><span class="op">)</span></span>
<span><span class="va">c_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">gene_exp</span>,<span class="va">`Disease Status`</span><span class="op">==</span><span class="st">"Control"</span><span class="op">)</span><span class="op">$</span><span class="va">`Gene 3`</span><span class="op">)</span></span>
<span><span class="va">g3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">gene_exp</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">`Disease Status`</span>, y<span class="op">=</span><span class="va">`Gene 3`</span>, color<span class="op">=</span><span class="va">`Disease Status`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x<span class="op">=</span><span class="fl">0</span>, xend<span class="op">=</span><span class="fl">3</span>, y<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">c_mean</span><span class="op">-</span><span class="va">pd_mean</span>, yend<span class="op">=</span><span class="fl">2</span><span class="op">*</span><span class="va">pd_mean</span><span class="op">-</span><span class="va">c_mean</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position<span class="op">=</span><span class="st">"none"</span><span class="op">)</span></span>
<span><span class="va">g1</span> <span class="op">|</span> <span class="va">g2</span> <span class="op">|</span> <span class="va">g3</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/lin%20model%203%20genes-1.png" width="672"></div>
<p>We can also compute the corresponding linear model fits, and confirm that the
coefficients agree with the directions observed in the plot, as well as that all
the associations are significant FDR &lt; 0.05:</p>
<div class="sourceCode" id="cb196"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">`Gene 1`</span> <span class="op">~</span> <span class="va">`Disease Status`</span>, data<span class="op">=</span><span class="va">gene_exp</span><span class="op">)</span></span>
<span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">`Gene 2`</span> <span class="op">~</span> <span class="va">`Disease Status`</span>, data<span class="op">=</span><span class="va">gene_exp</span><span class="op">)</span></span>
<span><span class="va">fit3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">`Gene 3`</span> <span class="op">~</span> <span class="va">`Disease Status`</span>, data<span class="op">=</span><span class="va">gene_exp</span><span class="op">)</span></span>
<span></span>
<span><span class="va">gene_stats</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_rows.html">bind_rows</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Gene 1"</span>,<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">4</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Gene 2"</span>,<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">fit2</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit2</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">4</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Gene 3"</span>,<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">fit3</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit3</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">gene_stats</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Gene"</span>,<span class="st">"Intercept"</span>,<span class="st">"Parkinson's"</span>,<span class="st">"pvalue"</span><span class="op">)</span></span>
<span><span class="va">gene_stats</span><span class="op">$</span><span class="va">padj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">gene_stats</span><span class="op">$</span><span class="va">pvalue</span>,method<span class="op">=</span><span class="st">"fdr"</span><span class="op">)</span></span>
<span><span class="va">gene_stats</span></span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   Gene   Intercept        `Parkinson's`     pvalue                   padj
##   &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;             &lt;chr&gt;                   &lt;dbl&gt;
## 1 Gene 1 250.410735540151 6.95982194659045  3.92131170913765e-06 3.92e- 6
## 2 Gene 2 597.763814010886 -93.6291659250254 2.37368730897756e-13 3.56e-13
## 3 Gene 3 334.57788193953  164.094204856583  1.72774902843408e-66 5.18e-66</code></pre>
<p>We have just performed our first elementary differential expression analysis
using a linear model. Specifically, we examined each of our genes for a
statistical relationship with having Parkinson’s disease. The mechanics of this
analysis are beyond the scope of this book, but later when we consider
differential expression analysis packages in <a href="biology-bioinformatics.html#biology-bioinformatics">chapter
7</a> this pattern should be familiar after this example.</p>
<div class="box note">
<p>If you are familiar with <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic
regression</a>, you might have
wondered why we didn’t model disease status, which is a binary variable, as a
function of gene expression like <code>Disease Status ~ Gene 3</code>. There are several
reasons for this, <a href="https://en.wikipedia.org/wiki/Separation_(statistics)">complete
separation</a> principally
among them. In logistic regression, complete separation occurs when all the
predictor values (e.g. gene expression) for one outcome group are greater or
smaller than the other; i.e. there is no overlap in the values between groups.
This causes logistic regression to fail to converge, leaving these genes with no
statistics even though these genes are potentially the most interesting! There
are methods (e.g. <a href="https://cran.r-project.org/web/packages/logistf/index.html">Firth’s Logistic
Regression</a>) that
overcome this problem, but methods that model gene expression as a function of
other outcome variables were developed first and remain the most popular.</p>
</div>
<div class="box readmore">
<p><a href="https://r4ds.had.co.nz/model-basics.html">Modeling Basics - R for Data Science</a>
<a href="https://en.wikipedia.org/wiki/Least_squares">Least squares regression</a></p>
</div>
</div>
<div id="flavors-of-linear-models" class="section level3" number="7.1.4">
<h3>
<span class="header-section-number">7.1.4</span> Flavors of Linear Models<a class="anchor" aria-label="anchor" href="#flavors-of-linear-models"><i class="fas fa-link"></i></a>
</h3>
<p>The linear model implemented above is termed <a href="https://en.wikipedia.org/wiki/Linear_regression">linear
regression</a> due to the way it
models the relationship between the predictor variables and the outcome.
Specifically, linear regression makes some strong assumptions about that
relationship that may not always hold for all datasets. To address this
limitation, a more flexible class of linear models called <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear
models</a> that allow these
assumptions to be relaxed by changing the mathematical relationship between the
predictors and outcome using a <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function">link
function</a>,
and/or by mathematically transforming the predictors themselves. Some of the
more common generalized linear models are listed below:</p>
<ul>
<li>
<strong>Logistic regression</strong> - models a binary outcome (e.g. disease vs control) as
a linear combination of predictor variables by using the <a href="https://en.wikipedia.org/wiki/Logistic_function">logistic
function</a> as the link function.</li>
<li>
<strong>Multinomial regression</strong> - models a multinomial (i.e. categorical variable
with more than two categories) using a <a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">multinomial logit function</a> link
function</li>
<li>
<strong>Poisson regression</strong> - models an outcome variable that are count data as
a linear combination of predictors using the logarithm as the link function;
this model is commonly used when modeling certain types of high throughput
sequencing data</li>
<li>
<strong>Negative binomial regression</strong> - also models an outcome variable that are
count data but relaxes some of the assumptions of Poisson regression, namely the
mean-variance equality constraint; negative binomial regression is commonly used
to model gene expression estimated from RNASeq data.</li>
</ul>
<p>Generalized linear models are very flexible, and there are many other types of
these models used in biology and data science. It is important to be aware of
the characteristics of the outcome you wish to model and choose the modeling
method that is most suitable.</p>
<div class="box readmore">
<p><a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized linear models</a></p>
</div>
</div>
<div id="assessing-model-accuracy-." class="section level3" number="7.1.5">
<h3>
<span class="header-section-number">7.1.5</span> Assessing Model Accuracy .<a class="anchor" aria-label="anchor" href="#assessing-model-accuracy-."><i class="fas fa-link"></i></a>
</h3>

</div>
</div>
<div id="statistical-distributions" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Statistical Distributions<a class="anchor" aria-label="anchor" href="#statistical-distributions"><i class="fas fa-link"></i></a>
</h2>
<p>Biological data, like all data, is uncertain. Measurements always contain noise,
but a collection of measurements do not always contain signal. The field of
statistics grew from the recognition that mathematics can be used to quantify
uncertainty and help us reason about whether a signal exists within a dataset,
and how certain we are of that signal. At its core, statistics is about
separating the signal from the noise of a dataset in a rigorous and precise way.</p>
<p>One of the fundamental statistical tools used when estimating uncertainty is the
<em>statistical distribution</em>, or <em>probability distribution</em>, or simply
<em>distribution</em>. There are two broad classes of distributions: statistical, or
theoretical, distributions and empirical distributions. In this section we will
discuss some general properties of distributions, briefly describe some common
probability distributions, and explain how to specify and use these
distributions in R.</p>
<div id="random-variables" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> Random Variables<a class="anchor" aria-label="anchor" href="#random-variables"><i class="fas fa-link"></i></a>
</h3>
<p>A random variable is an object or quantity which depends upon random events and
that can have samples drawn from it. For example, a six-sided die is a random
variable with six possible outcomes, and a single roll of the die will yield one
of those outcomes with some probability (equal probability, if the die is fair).
A coin is also a random variable, with heads or tails as the outcome. A gene’s
expression in a RNASeq experiment is a random variable, where the possible
outcomes are any non-negative integer corresponding to the number of reads that
map to it. In these examples, the outcome is a simple category or real number,
but random variables can be associated with more complex outcomes as well,
including trees, sets, shapes, sequences, etc. The probability of each outcome
is specified by the distribution associated with the random variable.</p>
<p>Random variables are usually notated as capital letters, like <span class="math inline">\(X,Y,Z,\)</span> etc. A
sample drawn from a random variable is usually notated as a lowercase of the
same letter, e.g. <span class="math inline">\(x\)</span> is a sample drawn from the random variable <span class="math inline">\(X\)</span>. The
distribution of a random variable is usually described like “<span class="math inline">\(X\)</span> follows a
binomial distribution” or “<span class="math inline">\(Y\)</span> is a normally distributed random variable”.</p>
<p>The probability of a random variable taking one of its possible values is
usually written <span class="math inline">\(P(X = x)\)</span>. The value of <span class="math inline">\(P(X = x)\)</span> is defined by the
distribution of <span class="math inline">\(X\)</span>. As we will see later in the <a href="data-science.html#p-values">p-values</a> section, sometimes
we are also interested in the probability of observing a value of <span class="math inline">\(x\)</span> or larger
(or smaller). These probabilities are written <span class="math inline">\(P(X &gt; x)\)</span> (or <span class="math inline">\(P(X &lt; x)\)</span>). How
these probabilities are computed is described in the next section.</p>
</div>
<div id="statistical-distribution-basics" class="section level3" number="7.2.2">
<h3>
<span class="header-section-number">7.2.2</span> Statistical Distribution Basics<a class="anchor" aria-label="anchor" href="#statistical-distribution-basics"><i class="fas fa-link"></i></a>
</h3>
<p>By definition, a statistical distribution is a function that maps <strong>the possible
values for a variable to how often they occur</strong>. Said differently, a statistical
distribution is used to compute the probability of seeing a single value, or a
range of values, relative to all other possible values, assuming the random
variable in question follows the statistical distribution. The following is a
visualization of the theoretical distribution of a normally distributed random
variable:</p>
<div class="sourceCode" id="cb198"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>,<span class="fl">4</span>,by<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span>,</span>
<span>  `Probability Density`<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">`Probability Density`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Probability Density Function for a Normal Distribution"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/stat%20normal-1.png" width="672"></div>
<p>The plot above depicts to the <em>probability density function</em> (PDF) of a normal
distribution with mean of zero and a standard deviation of one. The PDF defines
the probability associated with every possible value of <span class="math inline">\(x\)</span>, which for the
normal distribution is all real numbers. All PDFs have a closed mathematical
form. The PDF for the normal distribution is:</p>
<p><span class="math display">\[
P(X = x|\mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{\frac{-(x-\mu)^2}{2\sigma}}
\]</span></p>
<p>The notation <span class="math inline">\(P(X = x|\mu,\sigma)\)</span> is read like “the probability that the random
variable <span class="math inline">\(X\)</span> takes the value <span class="math inline">\(x\)</span>, given mean <span class="math inline">\(\mu\)</span> and standard deviation
<span class="math inline">\(\sigma\)</span>”. The normal distribution is an example of a <em>parametric distribution</em>
because its PDF requires two parameters - mean and standard deviation - to
compute probabilities. The choice of parameter values <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> in the
normal distribution determine the probability of the value of <span class="math inline">\(x\)</span>.</p>
<div class="box note">
<p>Probability density functions are defined for continuous distributions only,
as described later in this section. Discrete distributions have a probability
mass function (PMF) instead of a PDF, since the probability distribution is
subdivided into a set of different categories. PMFs have different mathematical
characteristics than PDFs (e.g. they are not continuous and therefore are not
differentiable), but serve the same purpose.</p>
</div>
<p>In probability theory, if a plausible event has a probability of zero, this
<em>does not mean that event can never occur</em>. In fact, every specific value in a
distribution that supports all real numbers has a probability of zero (i.e. one
specific value out of an infinite number of values). Instead, the probability
distribution function allows us to reason about the <em>relative likelihood</em> of
observing values in one range of the distribution compared with the others.
While most values have extremely small relative probabilities, they never are
equal to zero. This is due to the asymptotic properties of probability
distributions, where every <a href="https://en.wikipedia.org/wiki/Support_(mathematics)">supported
value</a> of the distribution
has a non-zero value by definition, though many values may be very close to
zero.</p>
<p>The PDF provides the probability density of specific values within the
distribution, but sometimes we are interested in the probability of a value
being less than or equal to a particular value. We compute this using the
<em>cumulative distribution function</em> (CDF) or sometimes just <em>distribution
function</em>. In the plot below, both the PDF and CDF are plotted for a normal
distribution with mean zero and standard deviation of 1:</p>
<div class="sourceCode" id="cb199"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>,<span class="fl">4</span>,by<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span>,</span>
<span>  PDF<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>,</span>
<span>  CDF<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">PDF</span>,color<span class="op">=</span><span class="st">"PDF"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">CDF</span>,color<span class="op">=</span><span class="st">"CDF"</span><span class="op">)</span>,linetype<span class="op">=</span><span class="st">"dashed"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/stat%20pdf%20cdf-1.png" width="672"></div>
<p>The value of the CDF corresponds to the area under the density curve up to the
corresponding value of <span class="math inline">\(x\)</span>; 1 minus that value is the area under the curve
greater than that value. The following figures illustrate this:</p>
<div class="inline-figure"><img src="main_files/stat%20cdfs-1.png" width="672"></div>
<p>91% of the probability density is less than the (arbitrary) value of <span class="math inline">\(x=1.37\)</span>,
and likewise 9% is greater. This is how <a href="data-science.html#p-values">p-values</a> are calculated, as described
later.</p>
<p>The CDF is also useful for generating samples from the distribution. In the
following plot, 1000 random samples were drawn from a uniform distribution in
the interval <span class="math inline">\((0,1)\)</span> and plotted using the inverse CDF function:</p>
<div class="inline-figure"><img src="main_files/stat%20inv%20cdf-1.png" width="672"></div>
<p>The histograms on the margins show the distributions of the <span class="math inline">\(p\)</span> and <span class="math inline">\(x\)</span> values
for the scatter points. The <span class="math inline">\(p\)</span> coordinates are uniform, while the <span class="math inline">\(x\)</span>
distribution is normal with mean of zero and standard deviation of one. In this
way, we can draw samples from a normal distribution, or any other distribution
that has an invertible CDF.</p>
</div>
<div id="distributions-in-r" class="section level3" number="7.2.3">
<h3>
<span class="header-section-number">7.2.3</span> Distributions in R<a class="anchor" aria-label="anchor" href="#distributions-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>There are four key operations we performed with the normal distribution in the
previous section:</p>
<ol style="list-style-type: decimal">
<li>Calculate probabilities using the PDF</li>
<li>Calculate cumulative probabilities using the CDF</li>
<li>Calculate the value associated with a cumulative probability</li>
<li>Sample values from a parameterized distribution</li>
</ol>
<p>In R, each of these operations has a dedicated function for each different
distribution, prefixed by <code>d</code>, <code>p</code>, <code>q</code>, and <code>r</code>. For the normal distribution,
these functions are <code>dnorm</code>, <code>pnorm</code>, <code>qnorm</code>, and <code>rnorm</code>:</p>
<ol style="list-style-type: decimal">
<li>
<code>dnorm(x, mean=0, sd=1)</code> - PDF of the normal distribution</li>
<li>
<code>pnorm(q, mean=0, sd=1)</code> - CDF of the normal distribution</li>
<li>
<code>qnorm(p, mean=0, sd=1)</code> - inverse CDF; accepts quantiles between 0 and 1 and returns the
value of the distribution for those quantiles</li>
<li>
<code>rnorm(n, mean=0, sd=1)</code> - generate <code>n</code> samples from a normal distribution</li>
</ol>
<p>R uses this scheme for all of its base distributions, which include:</p>
<div class="inline-table"><table style="width:71%;" class="table table-sm">
<colgroup>
<col width="27%">
<col width="43%">
</colgroup>
<thead><tr class="header">
<th>Distribution</th>
<th>Probability Density Function</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Normal</td>
<td><code>dnorm(x,mean,sd)</code></td>
</tr>
<tr class="even">
<td>t Distribution</td>
<td><code>dt(x,df)</code></td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td><code>dpois(n,lambda)</code></td>
</tr>
<tr class="even">
<td>Binomial</td>
<td><code>dbinom(x, size, prob)</code></td>
</tr>
<tr class="odd">
<td>Negative Binomial</td>
<td><code>dnbinom(x, size, prob, mu)</code></td>
</tr>
<tr class="even">
<td>Exponential</td>
<td><code>dexp(x, rate)</code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\chi^2\)</span></td>
<td><code>dchisq(x, df)</code></td>
</tr>
</tbody>
</table></div>
<p>There are <a href="https://www.stat.umn.edu/geyer/old/5101/rlook.html">many more distributions</a>
implemented in R beyond these, and they all follow the same scheme.</p>
<p>The next two sections will cover examples of some of these distributions.
Generally, statistical distributions are divided into two categories: discrete
distributions and continuous distributions.</p>
</div>
<div id="discrete-distributions" class="section level3" number="7.2.4">
<h3>
<span class="header-section-number">7.2.4</span> Discrete Distributions<a class="anchor" aria-label="anchor" href="#discrete-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>Discrete distributions are defined over countable, possibly infinite sets.
Common discrete distributions include binomial (e.g. coin flips), multinomial
(e.g. dice rolls), Poisson (e.g. number of WGS sequencing reads that map to a
specific locus), etc. Below we describe a few of these in detail.</p>
<div id="bernoulli-random-trail-and-more" class="section level4" number="7.2.4.1">
<h4>
<span class="header-section-number">7.2.4.1</span> Bernoulli random trail and more<a class="anchor" aria-label="anchor" href="#bernoulli-random-trail-and-more"><i class="fas fa-link"></i></a>
</h4>
<p>One of the examples for discrete random variable distribution is the <strong>Bernoulli</strong>
function. A Bernoulli trail has only 2 outcomes with probability <span class="math inline">\(p\)</span> and <span class="math inline">\((1-p)\)</span>.
Consider flipping a fair coin, and the random variable X can take value 0 or 1
indicating you get a head or a tail. If it’s a fair coin, we would expect the
<span class="math inline">\(Pr(X = 0) = Pr(X = 1) = 0.5\)</span>. Or, if we throw a die and we record X = 1 when
we get a six, and X = 0 otherwise, then <span class="math inline">\(Pr(X = 0) = 5/6\)</span> and <span class="math inline">\(Pr(X = 1) = 1/6\)</span>.</p>
<p>Now consider a slightly complicated situation: what if we are throwing the die
<span class="math inline">\(n\)</span> times and we would like to analyze the total number of six, say <span class="math inline">\(x\)</span>, we get
during those <span class="math inline">\(n\)</span> throws? Now, this leads us to the <strong>binomial distribution</strong>.
If it’s a fair die, we would say our proportion parameter <span class="math inline">\(p = 1/6\)</span>, which means
the probability we are getting a six is 1/6 for each throw.</p>
<p><span class="math display">\[
\begin{equation}
f(x) = \frac {n!} {x!(n-x)!}p^x (1-p) ^{(n-x)}
\end{equation}
\]</span></p>
<p>The <strong>geometric</strong> random variable, similar to the binomial, is also from a
sequence of random Bernoulli trials with a constant probability parameter <span class="math inline">\(p\)</span>.
But this time, we define the random variable <span class="math inline">\(X\)</span> as the number of consecutive
failures before the first success. In this case, the probability of <span class="math inline">\(x\)</span>
consecutive failures followed by success on trial <span class="math inline">\(x+1\)</span> is:</p>
<p><span class="math display">\[
\begin{equation}
f(x) = p * (1-p)^x
\end{equation}
\]</span></p>
<p>The <strong>negative binomial</strong> distribution goes one step forward. This time, we are
still performing a sequence of independent Bernoulli random trials with a
constant probability of success equal to <span class="math inline">\(p\)</span>. But now we would like to record
the random variable <span class="math inline">\(Z\)</span> to be the total number of failures before we finally get
to the <span class="math inline">\(r^{th}\)</span> success. In other words, when we get to the <span class="math inline">\(r^{th}\)</span> success, we
had <span class="math inline">\(x+r\)</span> Bernoulli random trails, in which <span class="math inline">\(x\)</span> times failed and <span class="math inline">\(r\)</span> times
succeeded.</p>
<p><span class="math display">\[
\begin{equation}
f(x) = \frac {x+r-1} {r-1} p^r {(1-p)}^x
\end{equation}
\]</span></p>
</div>
<div id="poisson" class="section level4" number="7.2.4.2">
<h4>
<span class="header-section-number">7.2.4.2</span> Poisson<a class="anchor" aria-label="anchor" href="#poisson"><i class="fas fa-link"></i></a>
</h4>
<p>The Poisson distribution is used to express the probability of a given number
of events occurring in a fixed interval of time or space, and these events
occur with a known constant mean rate and independently of the time since
the last event. <del>But no one understands this definition.</del></p>
<p>The formula for Poisson distribution is:</p>
<p><span class="math display">\[
\begin{equation}
f(k; \lambda) = Pr(X=k) = \frac {\lambda^k e^{-\lambda}} {k!}
\end{equation}
\]</span></p>
<ul>
<li>lambda is the expected value of the random variable X<br>
</li>
<li>k is the number of occurrences<br>
</li>
<li>e is Euler’s number (e=2.71828)<br><del>okay, the formula makes it even more confusing.</del>
</li>
</ul>
<p>Imagine you are working at a mail reception center, and your responsibility
is to receive incoming letters. Assume the number of incoming letters is not
affected by the day of the week or season of the year. You are expected to get
20 letters on average in a day. But, the actual number of letters you receive
each day will not be perfectly 20.</p>
<p>You recorded the number of letters you receive each day in a month (30 days).
In the following plot, each dot represents a day. The x-axis is calender day,
and y-axis is the number of letters you receive on that day. Although on average
you are receiving 20 letters each day, the actual number of letters each day
vary a lot.</p>
<div class="sourceCode" id="cb200"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">my_letter</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">30</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">my_letter</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"Letters received each day"</span>,</span>
<span>  xlab <span class="op">=</span> <span class="st">"day of the month"</span>, ylab <span class="op">=</span> <span class="st">"number of letters"</span>,</span>
<span>  pch <span class="op">=</span> <span class="fl">19</span>, col <span class="op">=</span> <span class="st">"royalblue"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">20</span>, b <span class="op">=</span> <span class="fl">0</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-51-1.png" width="672"></div>
<p>Now, let’s plot the density plot of our data. The <span class="math inline">\(x\)</span>-axis is the number of
letters on a single day, and the <span class="math inline">\(y\)</span>-axis is the probability.</p>
<div class="sourceCode" id="cb201"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">my_letter</span><span class="op">)</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"Probability of number of letters each day"</span>,</span>
<span>  xlab <span class="op">=</span> <span class="st">"number of letters"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-52-1.png" width="672"></div>
<p>Since we only have 30 data points, it doesn’t look like a good curve. But,
after we worked at the mail reception for 5000 days, it becomes much closer
to the theoretical Poisson distribution with lambda = 20.</p>
<div class="sourceCode" id="cb202"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5000</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"Probability of number of letters each day"</span>,</span>
<span>  xlab <span class="op">=</span> <span class="st">"number of letters"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-53-1.png" width="672"></div>
<p>Here is the theoretical Poisson distribution with lambda = 20:</p>
<div class="sourceCode" id="cb203"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">40</span><span class="op">)</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"royalblue"</span>,</span>
<span>  ylab <span class="op">=</span> <span class="st">"probability"</span>, main <span class="op">=</span> <span class="st">"Poisson lambda=20"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-54-1.png" width="672"></div>
<p>If we want to know what’s the probability to receive, for example, 18 letters,<br>
we can use <code><a href="https://rdrr.io/r/stats/Poisson.html">dpois()</a></code> function.</p>
<div class="sourceCode" id="cb204"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">18</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.08439355</code></pre>
<p>If we want to know the probability of receiving 18 or less letters,
use <code><a href="https://rdrr.io/r/stats/Poisson.html">ppois()</a></code> function.</p>
<div class="sourceCode" id="cb206"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">ppois</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">18</span>, lambda <span class="op">=</span> <span class="fl">20</span>, lower.tail <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.3814219</code></pre>
<p>It is the cumulative area colored in the following plot:</p>
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">40</span><span class="op">)</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"royalblue"</span>,</span>
<span>  ylab <span class="op">=</span> <span class="st">"probability"</span>, main <span class="op">=</span> <span class="st">"Poisson lambda=20"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html">polygon</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">18</span>, <span class="fl">18</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">18</span><span class="op">)</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>  border <span class="op">=</span> <span class="st">"royalblue"</span>, col <span class="op">=</span> <span class="st">"lightblue1"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="fl">18</span>, y0 <span class="op">=</span> <span class="fl">0</span>, y1 <span class="op">=</span> <span class="fl">0.08439355</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-57-1.png" width="672"></div>
<p><code><a href="https://rdrr.io/r/stats/Poisson.html">qpois()</a></code> is like the “reverse” of <code><a href="https://rdrr.io/r/stats/Poisson.html">ppois()</a></code>.</p>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">qpois</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fl">0.3814219</span>, lambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 18</code></pre>
<p>Let’s review the definition of Poisson distribution.</p>
<ul>
<li>“these events occur in a fixed interval of time or space”, which is a day;<br>
</li>
<li>“these events occur with a known constant mean rate”, which is 20 letters;<br>
</li>
<li>“independently of the time since the last event”, which means the number of
letters you receive today is independent of the letter you receive tomorrow.
<del>more work today don’t guarantee less work tomorrow, just like in real life</del>
</li>
</ul>
<p>Now let’s re-visit the formula.</p>
<p><span class="math display">\[
\begin{equation}
f(k; \lambda) = Pr(X=k) = \frac {\lambda^k e^{-\lambda}} {k!}
\end{equation}
\]</span></p>
<ul>
<li>lambda is the expected value of <span class="math inline">\(X\)</span>, which is 20 letters in this example.<br>
</li>
<li>
<span class="math inline">\(k\)</span> is the number of occurrences, which is the number of letters you get on a
specific day.</li>
<li>e is Euler’s number (e=2.71828)</li>
</ul>
</div>
</div>
<div id="continuous-distributions" class="section level3" number="7.2.5">
<h3>
<span class="header-section-number">7.2.5</span> Continuous Distributions<a class="anchor" aria-label="anchor" href="#continuous-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>In contrast with discrete distributions, continuous distributions are defined
over infinite, possibly bounded domains, e.g. all real numbers. There are a
number of different continuous distributions. Here we will focus on the <strong>Normal
distribution (Gaussian distribution)</strong>. A lot of variables in real life are
normally distributed, common examples include people’s height, blood pressure,
and students’ exam score.</p>
<p>This is what a normal distribution with mean = 0 and standard deviation = 1
looks like:</p>
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">norm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50000</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"A Normal distribution"</span>, xlab <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-59-1.png" width="672"></div>
<p>Similar as the Poisson distribution above, there are several functions to work
with normal distribution, including <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code>, <code><a href="https://rdrr.io/r/stats/Normal.html">dnorm()</a></code>, <code><a href="https://rdrr.io/r/stats/Normal.html">pnorm()</a></code>, and
<code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code>.</p>
<p><code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> is used to draw random data points from a normal distribution with
a given mean and standard deviation.</p>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span></span>
<span>  n <span class="op">=</span> <span class="fl">6</span>, <span class="co"># number of data points to draw</span></span>
<span>  mean <span class="op">=</span> <span class="fl">0</span>, <span class="co"># mean</span></span>
<span>  sd <span class="op">=</span> <span class="fl">1</span> <span class="co"># standard deviation</span></span>
<span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] -0.89691455  0.18484918  1.58784533 -1.13037567 -0.08025176  0.13242028</code></pre>
<p><code><a href="https://rdrr.io/r/stats/Normal.html">dnorm()</a></code> is the density at a given quantile. For instance, in the normal
distribution (mean=0, standard deviation=1) above, the probability density at
0.5 is roughly 0.35.</p>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.3520653</code></pre>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"A Normal distribution"</span>, xlab <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="fl">0.5</span>, y0 <span class="op">=</span> <span class="fl">0</span>, y1 <span class="op">=</span> <span class="fl">0.3520653</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, y0 <span class="op">=</span> <span class="fl">0.3520653</span>, x1 <span class="op">=</span> <span class="fl">0.5</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, y <span class="op">=</span> <span class="fl">0.3520653</span>, cex <span class="op">=</span> <span class="fl">1.5</span>, lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">1.1</span>, y <span class="op">=</span> <span class="fl">0.36</span>, labels <span class="op">=</span> <span class="st">"0.3521"</span>, col <span class="op">=</span> <span class="st">"red2"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-62-1.png" width="672"></div>
<p><code><a href="https://rdrr.io/r/stats/Normal.html">pnorm()</a></code> gives the distribution function. Or, you can think of it as the
cumulative of the left side of the density function until a given value,
which is the area colored in light blue in the following plot.</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">0.5</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.6914625</code></pre>
<div class="sourceCode" id="cb219"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span>,</span>
<span>  main <span class="op">=</span> <span class="st">"A Normal distribution"</span>, xlab <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>  lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html">polygon</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">0.5</span><span class="op">]</span>, <span class="fl">0.5</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span> <span class="op">&lt;=</span> <span class="fl">0.5</span><span class="op">]</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>  border <span class="op">=</span> <span class="st">"royalblue"</span>, col <span class="op">=</span> <span class="st">"lightblue1"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="fl">0.5</span>, y0 <span class="op">=</span> <span class="fl">0</span>, y1 <span class="op">=</span> <span class="fl">0.3520653</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-64-1.png" width="672"></div>
<p><code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code> gives the quantile function. You can think of it as the “reverse” of
<code><a href="https://rdrr.io/r/stats/Normal.html">pnorm()</a></code>. For instance:</p>
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">0.5</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.6914625</code></pre>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fl">0.6914625</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.5000001</code></pre>
<p>Similarly, other distributions such as chi-square distribution, they all have
the same set of functions: <code><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq()</a></code> and <code><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq()</a></code> etc.</p>
</div>
<div id="empirical-distributions" class="section level3" number="7.2.6">
<h3>
<span class="header-section-number">7.2.6</span> Empirical Distributions<a class="anchor" aria-label="anchor" href="#empirical-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>Empirical distributions describe the relative frequency of observed values in a
dataset. Empirical distributions may have any shape, and may be visualized using
any of the methods described in the <a href="data-visualization.html#visualizing-distributions">Visualizing Distributions</a> section, e.g. a
<a href="#density-plots">density plot</a>. The following beeswarm and density plot both
visualize the same made-up dataset:</p>
<div class="inline-figure"><img src="main_files/stat%20hist-1.png" width="672"></div>
<p>Note the <span class="math inline">\(y\)</span> axis in the plot on the right is scaled as a density, rather than a
count. A distribution plotted as a density ensures the values sum to 1, thus
making a probability distribution. This empirical distribution looks quite
complicated, and cannot be easily captured with a single mean and confidence
interval.</p>
</div>
</div>
<div id="statistical-tests" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Statistical Tests<a class="anchor" aria-label="anchor" href="#statistical-tests"><i class="fas fa-link"></i></a>
</h2>
<div id="what-is-a-statistical-test" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> What is a statistical test<a class="anchor" aria-label="anchor" href="#what-is-a-statistical-test"><i class="fas fa-link"></i></a>
</h3>
<p>A statistical test is an application of mathematics that we used to analyze
quantitative data. They can be described as a way to understand how the
independent variable(s) of the study affect the outcome of the dependent
variable. The kind of statistical test appropriate for a study depends on a
number of factors including variables characteristics, study design, and data
distribution. The independent variable is (are) the variable(s) being controlled
in the study to determine its effects on the dependent variable(s). Not all
studies have independent variable(s).</p>
<div id="study-design" class="section level4 unnumbered">
<h4>Study design<a class="anchor" aria-label="anchor" href="#study-design"><i class="fas fa-link"></i></a>
</h4>
<p>The number of conditions a study has corresponds to the number of levels the
independent variable has, for example 1 condition = 1 level, 2 conditions = 2
levels, and so on. This is different from the number of independent variables a
study has. If a study has multiple independent variables, each will have its own
number of levels. Statistical tests can be categorized as to whether they can
handle 1, 2, or 2+ levels.</p>
<p>If you have 2 or more levels, then the type of grouping will need to be
considered: are they between-subjects* or repeated-measures**. A between-subject
design means that each participant undergoes one condition whereas a
repeated-measures design has each participant undergo all conditions. A third
type exists called matched groups, where different subjects undergo different
conditions but are matched to each other in some important way, and may be
treated as a repeated-measure design when selecting for a statistical test</p>
<p><small>
*Independent design = between-subjects = between-groups; not to be confused with the variable.
**Dependent design = repeated-measures = within-subjects = within-groups; also not to be confused with the variable.
</small></p>
</div>
<div id="variables" class="section level4 unnumbered">
<h4>Variables<a class="anchor" aria-label="anchor" href="#variables"><i class="fas fa-link"></i></a>
</h4>
<p>The characteristics of your variables, both independent (predictor) and
dependent (descriptor), will help you choose which statistical test to use.
Specifically, the number of each, their type, and the level of measurement, will
help you narrow your choices to select the appropriate test.</p>
<div id="number-of-variables" class="section level5 unnumbered">
<h5>Number of Variables<a class="anchor" aria-label="anchor" href="#number-of-variables"><i class="fas fa-link"></i></a>
</h5>
<p>The number of both independent and dependent variables will affect which test
you select. Test selection will differ whether you have 1 or 2+ dependent
variables and 0, 1, or 2+ independent variables.</p>
</div>
<div id="types-of-data-continuous-and-categorical" class="section level5 unnumbered">
<h5>Types of Data (Continuous and Categorical)<a class="anchor" aria-label="anchor" href="#types-of-data-continuous-and-categorical"><i class="fas fa-link"></i></a>
</h5>
<p>Typically in bioinformatics, data is subdivided into 3 categories: Continuous,
Categorical, and Binary. Continuous data is data that can take real number
values within either a finite or infinite range. For example, height is a
continuous variable: 152.853288cm (60.1783 in), 182.9704cm (72.0356 in),
172.7cm(68in), 163cm(64.2in) and 145.647cm (57.3413 in) are all technically
valid heights. Categorical data is data that can be divided to categories or
groups such as (high, medium, and low) or (under10, 10-29, and 30+). Binary
data, data that can either be one thing or another (T/D, Y/N, 0/1, etc) falls
under the Categorical data umbrella though may get mentioned separately
elsewhere. Data that exists in sequential, positive integer form- such as number
of siblings- is called Discrete data (bonus 4th category!) but typically ends up
being treated as categorical data.</p>
</div>
<div id="levels-of-measurement" class="section level5 unnumbered">
<h5>Levels of Measurement<a class="anchor" aria-label="anchor" href="#levels-of-measurement"><i class="fas fa-link"></i></a>
</h5>
<p>The main levels of measurement in we use in statistics are Ratio, Interval,
Nominal, and Ordinal. Both Ratio and Interval levels have distance between
measurements defined; the biggest difference between the two is that Ratio
measurements have a meaningful zero value (and no negative numbers). Height in
inches or cm, Kelvin, and number of students in a class are all Ratio
measurements. Interval measurements do not have a meaningful zero. Celsius and
Fahrenheit both have arbitrary 0s- the freezing point of pure and (a specific
kind of) ocean water- making most standard temperature measurements type
Interval. Ordinal measurements have a meaningful order to their values but have
variable/imprecise distances between measurements, like socioeconomic status
(upper, middle, and lower) and days since diagnosis (under 10, 10-39, 40-99,
100+). Nominal measurements do not have meaningful order to their values, like
country of origin and yes/no. Ratio and Interval measurements are continuous
variables while Nominal and Ordinal measurements are categorical variables.</p>
</div>
</div>
<div id="data-distribution-parametric-vs-nonparametric" class="section level4 unnumbered">
<h4>Data Distribution (Parametric vs Nonparametric)<a class="anchor" aria-label="anchor" href="#data-distribution-parametric-vs-nonparametric"><i class="fas fa-link"></i></a>
</h4>
<p>This is the third factor to keep in mind for test selection and only applicable
for NON-nominal dependent variables. Parametric tests make the assumption that
the population the data is sourced from has a normal or Gaussian distribution.
These are powerful tests because of their data distribution assumption, with the
downside of only being able to be used in select cases. Nonparametric tests do
not assume a normal distribution and therefore can be used in a wide range of
cases, thought they are less likely to find significance in the results.</p>
</div>
</div>
<div id="common-statistical-tests" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> Common Statistical Tests<a class="anchor" aria-label="anchor" href="#common-statistical-tests"><i class="fas fa-link"></i></a>
</h3>
<p>Here are some common statistical tests and a quick overview as to how to run
them in R. If you would like more information about a specific test, links are
included in the descriptions</p>
<p>These are only some statistical tests. <a href="https://stats.oarc.ucla.edu/other/mult-pkg/whatstat/">Here’s a link to where you can find a
few more</a></p>
<p><a href="https://en.wikipedia.org/wiki/Category:Statistical_tests">And here’s a link to Wikipedia’s list of statistical tests if you want to
overload on statistical tests because it’s your new
hobby</a></p>
<div id="one-sample-t-test" class="section level4 unnumbered">
<h4>
<strong>One-Sample T-Test</strong><a class="anchor" aria-label="anchor" href="#one-sample-t-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, continuous [ratio and interval]</p>
<p><em>Independent Variables</em>: 0 variables</p>
<p><em>Design</em>: 1 group, 1 level</p>
<p><em>Parametric</em>: Yes</p>
<div class="box readmore">
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module7-T-tests/PH717-Module7-T-tests4.html">More t-test information shamelessly linked from SPH</a>
<a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_hypothesistest-means-proportions/BS704_HypothesisTest-Means-Proportions2.html#headingtaglink_1">Null and Alternate (Research) Hypotheses</a>
<a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/bs704_probability9.html">Z-values</a>(not mentioned but are in texts that fully explain t-tests)
One-Sample t-tests come in 3 flavors: two-tailed test, one-tailed test (upper tail), and one-tailed test (lower tail).</p>
</div>
<div class="sourceCode" id="cb224"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># One-sample t-test</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="co">#numeric vector of data </span></span>
<span>       mu <span class="op">=</span> <span class="fl">0</span>, <span class="co">#True value of the mean. Defaults to 0</span></span>
<span>       alternative <span class="op">=</span> <span class="st">"two.sided"</span>, <span class="co"># ("two.sided", "less", "greater") depending on which you want to use. Defaults to "two.sided</span></span>
<span>       conf.level <span class="op">=</span> <span class="fl">0.95</span> <span class="co">#1-alpha. Defaults to 0.95</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function allows for multiple kinds of t-tests. To use this
function to perform a one sample t-test, you will need a numeric vector of the
data you want to run the data on, the mean you want to compare it to, your
confidence level (1 - alpha), and your alternative hypothesis. The t-test, like
other kinds of t-tests, will compare the means by calculating the t-statistic,
p-value and confidence intervals of your data’s mean.</p>
<p><em>t</em>: The calculated t-statistic, uses formula : (mean(x) - mu)/(sd(x)*sqrt(n_samples))</p>
<p><em>df</em>: Degrees of Freedom. Calculated by: n_samples-1</p>
<p><em>p</em>: The p-value of the t-test as determined by the t-statistic and df on the <a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_hypothesistest-means-proportions/t-table.pdf">t-distribution table</a></p>
<p><em>(conf.level) percent confidence interval</em>: calculated interval where the true mean(x) is with conf.level % certainty.</p>
<p><em>sample estimates, mean of x</em>: The calculated mean of x</p>
<p>Accepting or rejecting the null hypothesis is a matter of determining if mean(x) is outside the percent confidence interval range, if it is then the p-value will determine the significance of the results.</p>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Example</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">x0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span> <span class="co">#rnorm(n_samples, true_mean, standard_deviation)</span></span>
<span></span>
<span><span class="va">ttestx0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x0</span>, mu <span class="op">=</span> <span class="fl">0</span>, alternative <span class="op">=</span> <span class="st">"two.sided"</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span> <span class="co">#actual running of the t-test</span></span>
<span><span class="co">#t.test(x0) yeilds the same results bc I used default values for mu, alternative, and conf.level</span></span>
<span></span>
<span><span class="va">tlessx0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x0</span>, mu <span class="op">=</span> <span class="fl">0</span>, alternative <span class="op">=</span> <span class="st">"less"</span>, conf.level <span class="op">=</span> <span class="fl">0.90</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/knit_print.html">knit_print</a></span><span class="op">(</span><span class="va">ttestx0</span><span class="op">)</span> <span class="co">#display t-test output via knitr</span></span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x0
## t = -1.4507, df = 99, p-value = 0.15
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.32331056  0.05021268
## sample estimates:
##  mean of x 
## -0.1365489</code></pre>
<p>In <code>t.test_x0</code>, we are running a two-tailed t-test on a vector of 100 doubles
generated with <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> where the intended mean is 0. Since this is a
two-tailed test, the <em>alternate</em> hypothesis is <code>mean(x0) != 0</code> while the <em>null</em>
hypothesis is <code>mean(x0) = 0</code></p>
<p>Since mu=0 and 0 is within the range (-.323, 0.050), we have failed to reject
the null hypothesis with this set of data</p>
</div>
<div id="unpaired-t-test" class="section level4 unnumbered">
<h4>
<strong>Unpaired T-Test</strong><a class="anchor" aria-label="anchor" href="#unpaired-t-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, continuous [ratio and interval]</p>
<p><em>Independent Variables</em>: 1</p>
<p><em>Design</em>: 2 groups, 2 levels</p>
<p><em>Parametric</em>: Yes</p>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># One-sample t-test</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="co">#numeric vector of data 1</span></span>
<span>       <span class="va">y</span>, <span class="co">#numeric vector of data 2</span></span>
<span>       alternative <span class="op">=</span> <span class="st">"two.sided"</span>, <span class="co"># ("two.sided", "less", "greater") depending on which you want to use. Defaults to "two.sided</span></span>
<span>       conf.level <span class="op">=</span> <span class="fl">0.95</span> <span class="co">#1-alpha. Defaults to 0.95</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The unpaired t-test functions similarly to the one-sample t-test except instead
of mu, it uses dataset y. Variance is assumed to be about equal between dataset
x and y.</p>
<div class="box readmore">
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module7-T-tests/Module7-ttests6.html">Moer information about unpaired t-tests here</a>
<a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module7-T-tests/Module7-ttests7.html">Another R guide for upaired t-tests</a></p>
</div>
<div class="sourceCode" id="cb228"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Unpaired t-test example</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">unpaired</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/knit_print.html">knit_print</a></span><span class="op">(</span><span class="va">unpaired</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  x and y
## t = -22.51, df = 197.83, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.308051 -2.775122
## sample estimates:
##  mean of x  mean of y 
## -0.1365489  2.9050374</code></pre>
<p>Output for an unpaired two sample t-test is similar to the output for the
one-sample. Mu is typically 0 (though one could change it with ‘mu = n’ in the
function call) and the test uses the confidence interval for (mean(x)-mean(y)),
which is (-3.308, -2.775). Since mu does not exist within the confidence
interval, the null hypothesis can be rejected.</p>
</div>
<div id="paired-t-test" class="section level4 unnumbered">
<h4>
<strong>Paired T-Test</strong><a class="anchor" aria-label="anchor" href="#paired-t-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, continuous [ratio and interval]</p>
<p><em>Independent Variables</em>: 1</p>
<p><em>Design</em>: 1 group, 2 levels</p>
<p><em>Parametric</em>: Yes</p>
<div class="sourceCode" id="cb230"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># One-sample t-test</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="co">#numeric vector of data 1</span></span>
<span>       <span class="va">y</span>, <span class="co">#numeric vector of data 2</span></span>
<span>       paired <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co">#defaults to FALSE</span></span>
<span>       alternative <span class="op">=</span> <span class="st">"two.sided"</span>, <span class="co"># ("two.sided", "less", "greater") depending on which you want to use. Defaults to "two.sided</span></span>
<span>       conf.level <span class="op">=</span> <span class="fl">0.95</span> <span class="co">#1-alpha. Defaults to 0.95</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The paired t-test works for matched and repeated-measures designs. Like the
unpaired t-test, it has a second data vector and does not need ‘mu’. When
running a paired t-test make sure that you specify that <code>paired = TRUE</code> when
calling the function and that x and y have the same length.</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module7-T-tests/Module7-ttests8.html#headingtaglink_2">More information about paired t-tests
here</a></p>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Unpaired t-test example</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">0</span>, <span class="fl">13</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">unpaired</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, paired <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/knit_print.html">knit_print</a></span><span class="op">(</span><span class="va">unpaired</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = -3.7956, df = 99, p-value = 0.0002539
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -7.126787 -2.233560
## sample estimates:
## mean difference 
##       -4.680174</code></pre>
<p>Similar to the unpaired t-test, the paired t-test looks at the differences
between x and y. Unlike the unpaired t-test, the statistic creates and runs its
test on a third set of data created from the differences of x and y. For an x
and y of length n, r would create a third data set of <code>new = ((x1-y1), (x2-y2),...(xn-1-yn-1), (xn-yn))</code> and run its testing with mean(new) and sd(new)</p>
</div>
<div id="chi-squared-test" class="section level4 unnumbered">
<h4>
<strong>Chi-Squared test</strong><a class="anchor" aria-label="anchor" href="#chi-squared-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, categorical</p>
<p><em>Independent Variables</em>: 1</p>
<p><em>Design</em>: 2 groups, 2 + levels</p>
<p><em>Parametric</em>: No</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTesting-ChiSquare/BS704_HypothesisTesting-ChiSquare3.html">More Information on Chi-Squared tests</a></p>
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#How to Run a chi-squared test</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="co"># numeric vector, matrix, or factor</span></span>
<span>           <span class="va">y</span> <span class="co"># numeric vector; ignored if x is a matrix; factor of the same length as x if x is a factor</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div id="chi-square-goodness-of-fit_-_-" class="section level4" number="7.3.2.1">
<h4>
<span class="header-section-number">7.3.2.1</span> __Chi-Square Goodness-Of-Fit_ _{-}<a class="anchor" aria-label="anchor" href="#chi-square-goodness-of-fit_-_-"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, categorical</p>
<p><em>Independent Variables</em>: 0</p>
<p><em>Design</em>: 1 group</p>
<p><em>Parametric</em>: No</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTesting-ChiSquare/BS704_HypothesisTesting-ChiSquare2.html#headingtaglink_1">More Information on Chi-Squared test on one sample</a></p>
<div class="sourceCode" id="cb234"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#How to Run a chi-square goodness of fit</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="co"># numeric vector</span></span>
<span>           p <span class="op">=</span> <span class="co">#list of probabilities, like c(10, 10, 10, 70)/100), same length as x</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The chi-squared goodness-of-fit can compare one set of outcomes to a given set of probabilities to determine the likelihood of the test probabilities differing from the given. The set of given probabilities constitutes the null hypothesis. In the below example, the dataset is the tested outcome frequencies: the number of times x[1], x[2], x[3], and x[4] were observed. If my null hypothesis says that each of the 4 should be observed an equal number of times, then the resulting chi-square test should will have a p-value of p&lt;0.001</p>
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">25</span>, <span class="fl">18</span>, <span class="fl">92</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">x</span>, p<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>, <span class="fl">25</span>, <span class="fl">25</span>, <span class="fl">25</span><span class="op">)</span><span class="op">/</span><span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  x
## X-squared = 117.43, df = 3, p-value &lt; 2.2e-16</code></pre>
</div>
<div id="wilcoxon-mann-whitney-test" class="section level4 unnumbered">
<h4>
<strong>Wilcoxon-Mann Whitney test</strong><a class="anchor" aria-label="anchor" href="#wilcoxon-mann-whitney-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, (ordinal, interval, or ratio)</p>
<p><em>Independent Variables</em>: 1</p>
<p><em>Design</em>: 2 groups, 2 levels</p>
<p><em>Parametric</em>: No</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/bs704_nonparametric4.html">More information here</a></p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="data-science.html#cb237-1" tabindex="-1"></a><span class="fu">wilcox.test</span>(x,<span class="co">#Numeric vector of data</span></span>
<span id="cb237-2"><a href="data-science.html#cb237-2" tabindex="-1"></a>            y <span class="co">#optional numeric vector of data)</span></span></code></pre></div>
</div>
<div id="wilcoxon-signed-ranks-test" class="section level4 unnumbered">
<h4>
<strong>Wilcoxon Signed Ranks test</strong><a class="anchor" aria-label="anchor" href="#wilcoxon-signed-ranks-test"><i class="fas fa-link"></i></a>
</h4>
<p><em>Dependent Variables</em>: 1, (ordinal, interval, or ratio)</p>
<p><em>Independent Variables</em>: 1</p>
<p><em>Design</em>: 1 groups, 2 levels</p>
<p><em>Parametric</em>: No</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/BS704_Nonparametric6.html">More information here</a></p>
<p>``<code>{r</code>eval=FALSE}</p>
<p>wilcox.test(x,#Numeric vector of data
y, #numeric vector of data from 2nd level- same length
paired = TRUE)</p>
<pre><code>
#### __One-Way ANOVA__ {-}


_Dependent Variables_: 1, continuous

_Independent Variables_: 1

_Design_: 2+ groups, 2+ levels

_Parametric_: Yes

[More information here](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTesting-ANOVA/BS704_HypothesisTesting-ANOVA4.html#headingtaglink_3)

``` r
summary(aov(formula, #formula specifying the model
            data #data frame containing the variables in the formula))</code></pre>
</div>
<div id="regressions" class="section level4 unnumbered">
<h4>
<strong>Regressions</strong><a class="anchor" aria-label="anchor" href="#regressions"><i class="fas fa-link"></i></a>
</h4>
</div>
<div id="factor-analysis" class="section level4 unnumbered">
<h4>
<strong>Factor Analysis</strong><a class="anchor" aria-label="anchor" href="#factor-analysis"><i class="fas fa-link"></i></a>
</h4>
</div>
</div>
<div id="choosing-a-test" class="section level3" number="7.3.3">
<h3>
<span class="header-section-number">7.3.3</span> Choosing a Test<a class="anchor" aria-label="anchor" href="#choosing-a-test"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>Look for your <em>Dependent Variable(s).</em> How many do you have? (1 or 2+)
<ul>
<li>Which ones exist on a continuum, where any fraction within the valid range is technically possible, though the actual data might have rounded? (Continuous vs Categorical)</li>
<li>For Categorical: If values do not have a definite order then it’s Nominal. Else it’s probably Ordinal</li>
</ul>
</li>
<li>Look for your <em>Independent Variable(s).</em> How many do you have? (0, 1, or 2+)
<ul>
<li>Define their types and level of measurement as described in 1a and then do 2b and 2c if you have 1 or more independent variables</li>
<li>How many conditions does each independent variable have? (= # of levels)</li>
<li>Does the same subject or (equivalent subjects) undergo each condition/level? (‘Yes’ -&gt; repeated-measures; ‘No’ -&gt; between-groups</li>
</ul>
</li>
<li>If you do not have nominal data, can you assume your data would have a normal distribution if you measured the general population? (‘Yes’-&gt; parametric; ‘No’ -&gt; non-parametric)</li>
</ol>
</div>
<div id="p-values" class="section level3" number="7.3.4">
<h3>
<span class="header-section-number">7.3.4</span> P-values<a class="anchor" aria-label="anchor" href="#p-values"><i class="fas fa-link"></i></a>
</h3>
<p>In statistics, the p-value is the probability of obtaining the observed results assuming that the null hypothesis is correct. In other words, the p-value is the probability of the same results happening by chance selection from the normal population rather than the test condition.</p>
<p>For instance, imagine there is a game that randomly picks one out of four colors. The game developer decides to add a 5th color, yellow, so that each color now has 1/5 chance of winning and a 4/5 chance of losing. How many of its first games would yellow have to lose in a row before you suspect the dev forgot to code in the ability for yellow to win? If you want to wait to until there is a &lt; 5% chance of yellow losing every single game in a row under normal circumstances before pointing this out to the dev, then yellow would have to lose 14/14 games (a 4.4% likelihood).</p>
<p>To visualize how 14 losses in a row in a game of chance with 1/5 success rate would occur in less than 5% of all instances, we can run a simulation of 1000 instances of 14 games with 1/5 chance success and displaying the results with their frequencies of success:</p>
<div class="sourceCode" id="cb239"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">roll</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">nrolls</span>, <span class="va">noptions</span><span class="op">)</span><span class="op">{</span></span>
<span> <span class="va">outcomes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">noptions</span>, <span class="va">nrolls</span>, <span class="cn">TRUE</span><span class="op">)</span></span>
<span> <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">outcomes</span><span class="op">[</span><span class="va">outcomes</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sample</span>, <span class="va">nrolls</span>, <span class="va">noptions</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">simulations</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">sample</span><span class="op">)</span><span class="op">{</span><span class="va">simulations</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">roll</span><span class="op">(</span><span class="va">nrolls</span>, <span class="va">noptions</span><span class="op">)</span><span class="op">}</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">simulations</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">18</span><span class="op">)</span></span>
<span><span class="va">Yellow_Wins</span> <span class="op">&lt;-</span> <span class="fu">dataset</span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">14</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">Yellow_Wins</span>, freq<span class="op">=</span><span class="cn">FALSE</span>, right<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure">
<img src="main_files/unnamed-chunk-77-1.png" width="672">
Here you see that slightly less than 5% of all run instances had 0 wins.</div>
<p>In this situation, we are comparing if yellow’s win rate is significantly lower than if yellow had an equal chance at winning. The research hypothesis or alternative hypothesis in this case is that yellow’s chance of winning is significantly lower than the rest of the colors while the null hypothesis would be that yellow’s chance of winning is the same as the rest of the colors.
The p-value of this test would be 0.043 because 43 out of 1000 instances of 14 rolls with a 1/5 chance of success totaled 0 successes, the number of successes we saw. If we instead were looking for 1 success or less out of 14 rolls, the p-value would be 0.19, because our simulation ran 147 instances of 1 success and 42 instances of 0 success.</p>
<p>Since p-values are calculated by the percentage of outcomes that are higher than the one observed, on a normal distribution they may look something like this:</p>
<div class="sourceCode" id="cb240"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">norm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50000</span>, mean <span class="op">=</span> <span class="fl">4</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"P-Values on a Normal Distribution"</span>, xlab <span class="op">=</span> <span class="st">"X-Values"</span>,</span>
<span>     lwd <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"royalblue"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html">polygon</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">6</span><span class="op">]</span>, <span class="fl">6</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">norm</span><span class="op">)</span><span class="op">$</span><span class="va">x</span> <span class="op">&gt;=</span> <span class="fl">6</span><span class="op">]</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>  border <span class="op">=</span> <span class="st">"royalblue"</span>, col <span class="op">=</span> <span class="st">"lightblue1"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span>x0 <span class="op">=</span> <span class="fl">6</span>, y0 <span class="op">=</span> <span class="fl">0</span>, y1 <span class="op">=</span> <span class="fl">0.4</span>, lwd <span class="op">=</span> <span class="fl">2</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"salmon"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">7</span>, <span class="fl">0.2</span>, <span class="st">"Observed Value (@ 2sd)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">3.9</span>, <span class="fl">0.01</span>, <span class="st">"Instances higher than crit. val -&gt;"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-78-1.png" width="672"></div>
<p>Here the observed value is 6, which happens to be exactly 2 standard deviations above the mean. To compute the p-value of this instance, the area under the curve would need to be calculated which can be easily done by looking up the appropriate values on a z-table. <a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/sas/sas4-onesamplettest/sas4-onesamplettest3.html">Here is a link about finding the area under the normal curve</a></p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module7-T-tests/PH717-Module7-T-tests3.html">SPH’s information about p-values here</a></p>
</div>
<div id="multiple-hypothesis-testing-." class="section level3" number="7.3.5">
<h3>
<span class="header-section-number">7.3.5</span> Multiple Hypothesis Testing .<a class="anchor" aria-label="anchor" href="#multiple-hypothesis-testing-."><i class="fas fa-link"></i></a>
</h3>
<p>What is multiply hypothesis testing adjustment? Why is it important? What are
some common adjustment methods (Bonferroni (FWER) and Benjamini-Hochberg (FDR))?
How do we interpret adjusted p-values (depends on the adjustment method)? How
do we compute adjusted p-values in R?</p>
</div>
<div id="statistical-power" class="section level3" number="7.3.6">
<h3>
<span class="header-section-number">7.3.6</span> Statistical power<a class="anchor" aria-label="anchor" href="#statistical-power"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Statistical Power</strong> is the probability that the null hypothesis was actually false but the data did not have enough evidence to reject it. In short, it is the failure to reject the null hypothesis in the presence of a significant effect. This is a Type II error, also known as a false negative. Its counterpart, the Type I error, is the probability that a null hypothesis was rejected when there was no significant effect.</p>
<p>The chance of a Type I error is represented by alpha, the same alpha that we use to calculate significance level (1-alpha). Type II errors are represented by beta. The relationship between statistical power and beta are similar to the relationship between significance level and alpha: statistical power is calculated as 1-beta.</p>
<p><a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_hypothesistest-means-proportions/BS704_HypothesisTest-Means-Proportions3.html#headingtaglink_3">Read more about the relationship between Type II and Type I errors</a></p>
<p>To calculate beta, find the area under the curve of the research hypothesis distribution on the opposite side of the critical value line where alpha is calculated. To find the area in the tail of the distribution, you would need to reference a Z-score chart, which will not be expected of you in this course. If you wish to read more about it <a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/sas/sas4-onesamplettest/sas4-onesamplettest3.html">here is a link about finding the area under the normal curve with z-scores, same one as linked above</a></p>
<p><img src="main_files/unnamed-chunk-79-1.png" width="672"><small> Code sourced from:
caracal, “How do I find the probability of a type II error”, stats.stackexchange.com, Feb 19, 2011, <a href="https://stats.stackexchange.com/questions/7402/how-do-i-find-the-probability-of-a-type-ii-error">link</a>, Date Accessed: Feb 28, 2022 </small></p>
<p>The above graph shows the relationship of alpha and beta. Since the alternative hypothesis is looking for a higher mean, alpha is calculated by the area under the null hypothesis curve on right side of the critical value while beta is calculated by the area under the alternative hypothesis on the left of the critical value line. Should an experiment get a higher p-value than the critical value, then the Beta will increase in relationship to Alpha decreasing.</p>
<div class="inline-figure">
<img src="main_files/unnamed-chunk-80-1.png" width="672">
In this graph, the critical value was moved to 0.025 while the null and alternative hypotheses stayed the same. As the chance of alpha decreased, the chances of beta increased. The opposite is also true, as alpha increases, beta decreases</div>
<div id="applications-of-statistical-power" class="section level5 unnumbered">
<h5>Applications of Statistical Power<a class="anchor" aria-label="anchor" href="#applications-of-statistical-power"><i class="fas fa-link"></i></a>
</h5>
<p>One of the applications of statistical power, besides as a measure of Type II error probability, is to allow you to run a power analysis. A power analysis involves using the relationship between <strong>Effect Size</strong>, <strong>Sample Size</strong>, <strong>Significance</strong>, and <strong>Statistical Power</strong> when you have three of the four parts in order to find the value of the fourth. This is typically used to find the effect size of a study, as that is often the hardest to estimate, or to find a sample size that corresponds with a desired effect size when designing a study.
<a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Power/BS704_Power6.html">Further reading on statistical power and power analysis</a></p>
</div>
<div id="effect-size" class="section level5 unnumbered">
<h5>Effect Size<a class="anchor" aria-label="anchor" href="#effect-size"><i class="fas fa-link"></i></a>
</h5>
<p>The effect size is a measurement of the magnitude of experimental effects. There are a number of ways to calculate effect size including but not limited to Cohen’s D, Pearson’s R, and Odds Ratio. If you would like to read about what BU’s SPH has to say about it, <a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_power/BS704_Power8.html">here is the SPH module link</a></p>
<p><small>
Citations:
Dorey FJ. Statistics in brief: Statistical power: what is it and when should it be used?. Clin Orthop Relat Res. 2011;469(2):619-620. <a href="doi:10.1007/s11999-010-1435-0" class="uri">doi:10.1007/s11999-010-1435-0</a></small></p>
<p>Parab S, Bhalerao S. Choosing statistical test. Int J Ayurveda Res. 2010;1(3):187-191. <a href="doi:10.4103/0974-7788.72494" class="uri">doi:10.4103/0974-7788.72494</a>
Introduction to SAS. UCLA: Statistical Consulting Group. from <a href="https://stats.idre.ucla.edu/sas/modules/sas-learning-moduleintroduction-to-the-features-of-sas/" class="uri">https://stats.idre.ucla.edu/sas/modules/sas-learning-moduleintroduction-to-the-features-of-sas/</a> (accessed February 24, 2022)</p>
<p>Ranganathan P, Gogtay NJ. An Introduction to Statistics - Data Types, Distributions and Summarizing Data. Indian J Crit Care Med. 2019 Jun;23(Suppl 2):S169-S170. doi: 10.5005/jp-journals-10071-23198. PMID: 31485129; PMCID: PMC6707495.</p>
<p></p>

</div>
</div>
</div>
<div id="exploratory-data-analysis" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Exploratory Data Analysis<a class="anchor" aria-label="anchor" href="#exploratory-data-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>So far, we have discussed methods where we chose an explicit model to summarize
our data. However, sometimes we don’t have enough information about our data to
propose reasonable models, as we did earlier when exploring the distribution of
our imaginary gene expression dataset. There may be patterns in the data that
emerge when we compute different summaries and ask whether there is a non-random
structure to how the individual samples or features compare with one another.
The types of methods we use to take a dataset and examine it for structure
without a prefigured hypothesis is called <em>exploratory analysis</em> and is a key
approach to working with biological data.</p>
<div id="principal-component-analysis" class="section level3" number="7.4.1">
<h3>
<span class="header-section-number">7.4.1</span> Principal Component Analysis<a class="anchor" aria-label="anchor" href="#principal-component-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>A very common method of exploratory analysis is <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component
analysis</a> or PCA.
PCA is a statistical procedure that identifies so called <em>directions of
orthogonal variance</em> that capture covariance between different dimensions in a
dataset. Because the approach captures this covariance between features of
arbitrary dimension, it is often used for so-called <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimensionality
reduction</a>, where a
large amount of variance in a dataset with a potentially large number of
dimensions may be expressed in terms of a set of <a href="https://en.wikipedia.org/wiki/Change_of_basis">basis
vectors</a> of smaller dimension.
The mathematical details of this approach are beyond the scope of this book, but
below we explain in general terms the intuition behind what PCA does, and
present an example of how it is used in a biological context.</p>
<p>PCA decomposes a dataset into a set of <a href="https://en.wikipedia.org/wiki/Orthonormal_basis">orthonormal basis
vectors</a> that collectively
capture all the variance in the dataset, where the first basis vector, called
the <em>first principal component</em> explains the largest fraction of the variance,
the second principal component explains the second largest fraction, and so on.
There are always an equal number of principal components as there are dimensions
in the dataset or the number of samples, whichever is smaller. Typically only a
small number of these components are needed to explain most of the variance.</p>
<p>Each principal component is a <span class="math inline">\(p\)</span>-dimensional <a href="https://en.wikipedia.org/wiki/Unit_vector">unit
vector</a> (i.e. a vector of magnitude
1), where <span class="math inline">\(p\)</span> is the number of features in the dataset, and the values are
weights that describe the component’s direction of variance. By multiplying this
component with the values in each sample, we obtain the <em>projection</em> of each
sample with respect to the basis of the component. The projections of each
sample made with each principal component produces a rotation of the dataset in
<span class="math inline">\(p\)</span> dimensional space. The figure below presents a geometric intuition of PCA.</p>
<div class="float">
<img src="PCA.png" alt="Principal Component Analysis - Geometric Intuition Illustration"><div class="figcaption">Principal Component Analysis - Geometric Intuition Illustration</div>
</div>
<p>Many biological datasets, especially those that make genome-wide measurements
like with gene expression assays, have many thousands of features (e.g. genes)
and comparatively few samples. Since PCA can only determine a maximum number of
principal components as the smaller of the number of features or samples, we
will almost always only have as many components as samples. To demonstrate this,
we perform PCA using the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp"><code>stats::prcomp()</code></a>
function on an example microarray gene expression intensity dataset:</p>
<div class="sourceCode" id="cb241"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># intensities contains microarray expression data for ~54k probesets x 20 samples</span></span>
<span></span>
<span><span class="co"># transpose expression values so samples are rows</span></span>
<span><span class="va">expr_mat</span> <span class="op">&lt;-</span> <span class="va">intensities</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">probeset_id</span><span class="op">)</span>,names_to<span class="op">=</span><span class="st">"sample"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">pivot_wider</span><span class="op">(</span>names_from<span class="op">=</span><span class="va">probeset_id</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># PCA expects all features (i.e. probesets) to be mean-centered,</span></span>
<span><span class="co"># convert to dataframe so we can use rownames</span></span>
<span><span class="va">expr_mat_centered</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">expr_mat</span>,<span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">sample</span><span class="op">)</span><span class="op">)</span>,<span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">expr_mat_centered</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">expr_mat</span><span class="op">$</span><span class="va">sample</span></span>
<span></span>
<span><span class="co"># prcomp performs PCA</span></span>
<span><span class="va">pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span></span>
<span>  <span class="va">expr_mat_centered</span>,</span>
<span>  center<span class="op">=</span><span class="cn">FALSE</span>, <span class="co"># prcomp centers features to have mean zero by default, but we already did it</span></span>
<span>  scale<span class="op">=</span><span class="cn">TRUE</span> <span class="co"># prcomp scales each feature to have unit variance</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># the str() function prints the structure of its argument</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">pca</span><span class="op">)</span></span></code></pre></div>
<pre><code>## List of 5
##  $ sdev    : num [1:20] 101.5 81 71.2 61.9 57.9 ...
##  $ rotation: num [1:54675, 1:20] 0.00219 0.00173 -0.00313 0.00465 0.0034 ...
##   ..- attr(*, "dimnames")=List of 2
##   .. ..$ : chr [1:54675] "X1007_s_at" "X1053_at" "X117_at" "X121_at" ...
##   .. ..$ : chr [1:20] "PC1" "PC2" "PC3" "PC4" ...
##  $ center  : logi FALSE
##  $ scale   : Named num [1:54675] 0.379 0.46 0.628 0.272 0.196 ...
##   ..- attr(*, "names")= chr [1:54675] "X1007_s_at" "X1053_at" "X117_at" "X121_at" ...
##  $ x       : num [1:20, 1:20] -67.94 186.14 6.07 -70.72 9.58 ...
##   ..- attr(*, "dimnames")=List of 2
##   .. ..$ : chr [1:20] "A1" "A2" "A3" "A4" ...
##   .. ..$ : chr [1:20] "PC1" "PC2" "PC3" "PC4" ...
##  - attr(*, "class")= chr "prcomp"</code></pre>
<p>The result of <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> is a list with five members:</p>
<ul>
<li>
<code>sdev</code> - the standard deviation (i.e. the square root of the variance) for each component</li>
<li>
<code>rotation</code> - a matrix where the principal components are in columns</li>
<li>
<code>x</code> - the projections of the original data, aka the rotated data matrix</li>
<li>
<code>center</code> - if <code>center=TRUE</code> was passed, a vector of feature means</li>
<li>
<code>scale</code> - if <code>scale=TRUE</code> was passed, a vector of the feature variances</li>
</ul>
<p>Recall that each principal component explains a fraction of the overall variance
in the dataset. The <code>sdev</code> variable returned by <code><a href="https://rdrr.io/r/stats/prcomp.html">prcomp()</a></code> may be used to first
calculate the variance explained by each component by squaring it, then dividing
by the sum:</p>
<div class="sourceCode" id="cb243"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="va">pca_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>  PC<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu">str_c</span><span class="op">(</span><span class="st">"PC"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span>,<span class="fu">str_c</span><span class="op">(</span><span class="st">"PC"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  Variance<span class="op">=</span><span class="va">pca</span><span class="op">$</span><span class="va">sdev</span><span class="op">**</span><span class="fl">2</span>,</span>
<span>  `% Explained Variance`<span class="op">=</span><span class="va">Variance</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">Variance</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span>,</span>
<span>  `Cumulative % Explained Variance`<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumsum</a></span><span class="op">(</span><span class="va">`% Explained Variance`</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">exp_g</span> <span class="op">&lt;-</span> <span class="va">pca_var</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC</span>,y<span class="op">=</span><span class="va">`% Explained Variance`</span>,group<span class="op">=</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>angle<span class="op">=</span><span class="fl">90</span>,hjust<span class="op">=</span><span class="fl">0</span>,vjust<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="co"># make x labels rotate 90 degrees</span></span>
<span></span>
<span><span class="va">cum_g</span> <span class="op">&lt;-</span> <span class="va">pca_var</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC</span>,y<span class="op">=</span><span class="va">`Cumulative % Explained Variance`</span>,group<span class="op">=</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span> <span class="op">+</span> <span class="co"># set y limits to [0,100]</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>angle<span class="op">=</span><span class="fl">90</span>,hjust<span class="op">=</span><span class="fl">0</span>,vjust<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">exp_g</span> <span class="op">|</span> <span class="va">cum_g</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20var-1.png" width="672"></div>
<p>The first component explains nearly 20% of all variance in the dataset, followed
by the second component with about 12%, the third component 9%, and so on. The
cumulative variance plot on the right shows that the top 15 components are
required to capture 90% of the variance in the dataset. This suggests that each
sample contributes a significant amount of variance to the overall dataset, but
that there are still some features that covary among them.</p>
<p>An important use of PCA results is the identification of outlier samples. This
is accomplished by plotting the projections of each sample and examining the
result by eye to identify samples that are “far away” from the other samples.
This is usually done by inspection and outlier samples chosen subjectively;
there are no general rules to decide when a sample is an outlier by this method.
Below the projections for components 1 and 2 are plotted against each other as a
scatter plot:</p>
<div class="sourceCode" id="cb244"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC1</span>,y<span class="op">=</span><span class="va">PC2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20pairwise-1.png" width="672"></div>
<p>By eye, no samples appear to be obvious outliers. However, this plot is just one
of many pairs of projections. We could plot all pairs of the first six
components using the <a href="https://ggobi.github.io/ggally/reference/ggpairs.html"><code>ggpairs() function</code></a> in the
<a href="https://ggobi.github.io/ggally/">GGally</a> package:</p>
<div class="sourceCode" id="cb245"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggobi.github.io/ggally/">GGally</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">PC1</span><span class="op">:</span><span class="va">PC6</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggobi.github.io/ggally/reference/ggpairs.html">ggpairs</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20pairs-1.png" width="672"></div>
<p>This is already nearly unintelligible and mostly uninformative. While it is very
common for projections for pairs of components to be plotted, an alternative way
to visualize projections across all samples is by plotting the distribution of
projections for each component using a <a href="#beeswarm-plots">beeswarm plot</a>:</p>
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html">everything</a></span><span class="op">(</span><span class="op">)</span>,names_to<span class="op">=</span><span class="st">"PC"</span>,values_to<span class="op">=</span><span class="st">"projection"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>PC<span class="op">=</span><span class="fu">fct_relevel</span><span class="op">(</span><span class="va">PC</span>,<span class="fu">str_c</span><span class="op">(</span><span class="st">"PC"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC</span>,y<span class="op">=</span><span class="va">projection</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"PCA Projection Plot"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>angle<span class="op">=</span><span class="fl">90</span>,hjust<span class="op">=</span><span class="fl">0</span>,vjust<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20proj%20beeswarm-1.png" width="672"></div>
<p>Now we can see all the projections for all components in the same plot, although
we cannot see how they relate to one another.</p>
<p>These projection plots may become more useful if we layer on additional
information about our samples. There are two types of samples in our dataset (
labelled <code>A</code> and <code>C</code>. We can color our pairwise scatter plot by type like so:</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_sub.html">str_sub</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC1</span>,y<span class="op">=</span><span class="va">PC2</span>,color<span class="op">=</span><span class="va">type</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20color%20scatter-1.png" width="672"></div>
<p>Little pattern is obvious from the plot, but we can plot pairs of components as
before but now with type information:</p>
<div class="sourceCode" id="cb248"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggobi.github.io/ggally/">GGally</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_sub.html">str_sub</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">type</span>,<span class="va">PC1</span><span class="op">:</span><span class="va">PC6</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggobi.github.io/ggally/reference/ggpairs.html">ggpairs</a></span><span class="op">(</span>columns<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>,mapping<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>fill<span class="op">=</span><span class="va">type</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20pairs%20type-1.png" width="672"></div>
<p>Examining PC3 and PC4, we now observe that there may indeed be some genes that
distinguish between types based on the separation of projection scores for the
two types. Finally, we can also color our beeswarm plot by type:</p>
<div class="sourceCode" id="cb249"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    sample<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>,</span>
<span>    type<span class="op">=</span><span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_sub.html">str_sub</a></span><span class="op">(</span><span class="va">sample</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span><span class="va">PC1</span><span class="op">:</span><span class="va">PC20</span>,names_to<span class="op">=</span><span class="st">"PC"</span>,values_to<span class="op">=</span><span class="st">"projection"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>PC<span class="op">=</span><span class="fu">fct_relevel</span><span class="op">(</span><span class="va">PC</span>,<span class="fu">str_c</span><span class="op">(</span><span class="st">"PC"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">PC</span>,y<span class="op">=</span><span class="va">projection</span>,color<span class="op">=</span><span class="va">type</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/ggbeeswarm/man/geom_beeswarm.html">geom_beeswarm</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"PCA Projection Plot"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>axis.text.x<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>angle<span class="op">=</span><span class="fl">90</span>,hjust<span class="op">=</span><span class="fl">0</span>,vjust<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/pca%20proj%20beeswarm%20type-1.png" width="672"></div>
<p>These approaches to plotting the results of a PCA are complementary, and all
may be useful in understanding the structure of a dataset.</p>
</div>
<div id="cluster-analysis" class="section level3" number="7.4.2">
<h3>
<span class="header-section-number">7.4.2</span> Cluster Analysis<a class="anchor" aria-label="anchor" href="#cluster-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>Cluster analysis or simple clustering is the task of grouping objects together
such that objects within the same group, or <em>cluster</em>, are more similar to each
other than to objects in other clusters. It is a type of <a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis">exploratory data
analysis</a> that seeks to
identify structure or organization in a dataset without making strong
assumptions about the data or testing a specific hypothesis. Many different
<a href="https://en.wikipedia.org/wiki/Category:Cluster_analysis_algorithms">clustering algorithms</a>
have been developed that employ different computational strategies and are
designed for data with different types and properties. The choice of algorithm
is often dependent upon not only the type of data being clustered but also the
comparative performance of different clustering algorithms applied to the same
data. Different algorithms may identify different types of patterns, and so no
one clustering method is better than any other in general.</p>
<p>The goal of clustering may be easily illustrated with the following plot:</p>
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">unclustered</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">well_clustered_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">f1</span>,y<span class="op">=</span><span class="va">f2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Unclustered"</span><span class="op">)</span></span>
<span><span class="va">clustered</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">well_clustered_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">f1</span>,y<span class="op">=</span><span class="va">f2</span>,color<span class="op">=</span><span class="va">cluster</span>,shape<span class="op">=</span><span class="va">cluster</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Clustered"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">unclustered</span> <span class="op">|</span> <span class="va">clustered</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/clustering%20goal-1.png" width="672"></div>
<p>That is, the goal of clustering is to take unlabeled data that has some
structure like on the left and label data points that are similar to one another
to be in the same cluster. A full treatment of cluster analysis is beyond the
scope of this book, but below we discuss a few of the most common and general
clustering algorithms used in biology and bioinformatics.</p>
<div id="hierarchical-clustering" class="section level4" number="7.4.2.1">
<h4>
<span class="header-section-number">7.4.2.1</span> Hierarchical Clustering<a class="anchor" aria-label="anchor" href="#hierarchical-clustering"><i class="fas fa-link"></i></a>
</h4>
<p>Hierarchical clustering is a form of clustering that clusters data points
together in nested, or <em>hierarchical</em>, groups based on their dissimilarity from
one another. There are two broad strategies to accomplish this:</p>
<ul>
<li>
<strong>Agglomerative</strong>: all data points start in their own groups, and groups are
iteratively merged hierarchically into larger groups based on their similarity
until all data points have been added to a group</li>
<li>
<strong>Divisive</strong>: all data points start in the same group, and are recursively
split into smaller groups based on their dissimilarity</li>
</ul>
<p>Whichever approach is used, the critical step in clustering is choosing the
<a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">distance function</a> that
quantifies how dissimilar two data points are. Distance functions, or <em>metrics</em>
are non-negative real numbers whose magnitude is proportional to some notion of
distance between a pair of points. There are <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)#Generalized_metrics">many different distance
functions</a>
to choose from, and the choice is made based on the type of data being
clustered. For numeric data, <a href="https://en.wikipedia.org/wiki/Euclidean_distance">euclidean
distance</a>, which corresponds
to the length of a line segment drawn between two points in any <span class="math inline">\(n\)</span>-dimensional
<a href="https://en.wikipedia.org/wiki/Euclidean_space">Euclidean space</a> is often a
reasonable choice.</p>
<p>Because the divisive strategy is conceptually the inverse of
agglomerative clustering, we will limit our description to agglomerative
clustering. Once the distance function has been chosen, distances between all
pairs of points are computed and the two nearest points are merged into a group.
The new group of points is used for computing distances to all other points as a
set using a <em>linkage function</em>
which defines how the group is summarized into a single point for the purposes
of distance calculation. The linkage function is what distinguishes different
clustering algorithms, which include:</p>
<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Single-linkage_clustering">Single-linkage</a> - distance between two groups is computed as the distance between the two nearest members of the groups</li>
<li>
<a href="https://en.wikipedia.org/wiki/Complete-linkage_clustering">Complete-linkage</a> - distance between two groups is computed as the distance between the two farthest members of the groups</li>
<li>
<a href="https://en.wikipedia.org/wiki/UPGMA">Unweighted Pair Group Method with Arithmetic mean (UPGMA)</a> - distance between two groups is the average distance of all pairs of points between groups</li>
<li>
<a href="https://en.wikipedia.org/wiki/WPGMA">Weighted Pair Group Method with Arithmetic mean (WPGMA)</a> - similar to UPGMA, but weights distances from pairs of groups evenly when merging</li>
</ul>
<p>The choice of linkage function (and therefore clustering algorithm) should be
determined based on knowledge of the dataset and assessment of clustering
performance. In general, there is no one linkage function that will always
perform well.</p>
<p>The following figure illustrates a simple example of clustering a 1 dimensional
set of points using WPGMA:</p>
<div class="float">
<img src="hierarchical_clustering.png" alt="Conceptual illustration of agglomerative hierarchical clustering"><div class="figcaption">Conceptual illustration of agglomerative hierarchical clustering</div>
</div>
<p>Below we will cluster the synthetic dataset introduced above in R:</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">well_clustered_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">f1</span>,y<span class="op">=</span><span class="va">f2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Unclustered"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/hclust%20data-1.png" width="672"></div>
<p>This synthetic dataset has two distinct groups of samples drawn from
multivariate normal samples. To hierarchically cluster these samples, we use the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/dist"><code>dist()</code></a>
and <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/hclust"><code>hclust()</code></a>
functions:</p>
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># compute all pairwise distances using euclidean distance as the distance metric</span></span>
<span><span class="va">euc_dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">well_clustered_data</span>,<span class="op">-</span><span class="va">ID</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># produce a clustering of the data using the hclust for hierarchical clustering</span></span>
<span><span class="va">hc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">euc_dist</span>, method<span class="op">=</span><span class="st">"ave"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># add ID as labels to the clustering object</span></span>
<span><span class="va">hc</span><span class="op">$</span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="va">well_clustered_data</span><span class="op">$</span><span class="va">ID</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">hc</span><span class="op">)</span></span></code></pre></div>
<pre><code>## List of 7
##  $ merge      : int [1:59, 1:2] -50 -33 -48 -46 -44 -21 -11 -4 -36 -3 ...
##  $ height     : num [1:59] 0.00429 0.08695 0.23536 0.24789 0.25588 ...
##  $ order      : int [1:60] 8 9 7 6 19 18 11 16 4 14 ...
##  $ labels     : chr [1:60] "A1" "A2" "A3" "A4" ...
##  $ method     : chr "average"
##  $ call       : language hclust(d = euc_dist, method = "ave")
##  $ dist.method: chr "euclidean"
##  - attr(*, "class")= chr "hclust"</code></pre>
<p>The <code><a href="https://rdrr.io/r/stats/hclust.html">hclust()</a></code> return object describes the clustering as a tree that can be
visualized using a <a href="data-visualization.html#dendrograms">dendrogram</a>:</p>
<div class="sourceCode" id="cb254"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://andrie.github.io/ggdendro/">ggdendro</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://andrie.github.io/ggdendro/reference/ggdendrogram.html">ggdendrogram</a></span><span class="op">(</span><span class="va">hc</span><span class="op">)</span></span></code></pre></div>
<p><img src="main_files/hclust%20dendro-1.png" width="672">
Our data do indeed cluster well, where all samples from the same group cluster
together perfectly. See the <a href="data-visualization.html#dendrograms">dendrogram</a> section in the <a href="#data-viz">data
vizualization chapter</a> for more detail on how to plot clustering
results.</p>
<p>It is sometimes desirable to use split hierarchical clustering into groups based
on their pattern. In the above clustering, three discrete clusters corresponding
sample groups are clearly visible. If we wished to separate these three groups,
we can use the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/cutree"><code>cutree</code></a>
to divide the tree into three groups using <code>k=3</code>:</p>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hc</span>,k<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">labels</span></span></code></pre></div>
<pre><code>##  A1  A2  A3  A4  A5  A6  A7  A8  A9 A10 A11 A12 A13 A14 A15 A16 A17 A18 A19 A20 
##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 
##  B1  B2  B3  B4  B5  B6  B7  B8  B9 B10 B11 B12 B13 B14 B15 B16 B17 B18 B19 B20 
##   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2 
##  C1  C2  C3  C4  C5  C6  C7  C8  C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 C19 C20 
##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3</code></pre>
<p>We can then use these samples and labels to color our original plot as desired:</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># we turn our labels into a tibble so we can join them with the original tibble</span></span>
<span><span class="va">well_clustered_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html">left_join</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>      ID<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">labels</span><span class="op">)</span>,</span>
<span>      label<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">labels</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">f1</span>,y<span class="op">=</span><span class="va">f2</span>,color<span class="op">=</span><span class="va">label</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Clustered"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/hclust%20cutree%20color-1.png" width="672"></div>
<p>We were able to recover the correct clustering because this dataset was easy to
cluster by construction. Real data are seldom so well behaved.</p>
</div>
</div>
<div id="k-means-." class="section level3" number="7.4.3">
<h3>
<span class="header-section-number">7.4.3</span> k-means .<a class="anchor" aria-label="anchor" href="#k-means-."><i class="fas fa-link"></i></a>
</h3>
</div>
<div id="others" class="section level3" number="7.4.4">
<h3>
<span class="header-section-number">7.4.4</span> Others<a class="anchor" aria-label="anchor" href="#others"><i class="fas fa-link"></i></a>
</h3>

</div>
</div>
<div id="network-analysis" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> Network Analysis<a class="anchor" aria-label="anchor" href="#network-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>The basic components of a network are <strong>vertex (or node)</strong>, which is the
features or subjects we are interested in. The <strong>edges</strong> are connections between
the vertices. In a general context, one example is the relationship network. The
vertices are people. If two people are friends, we draw an edge to connect them.
In a biology context, the vertices may be genes, and edges represent whether
there are any correlations between two genes.</p>
<p>Vertices and edges can have attributes. For example, in a social interaction
network, we may assign different colors to the vertices according to a student’s
major. When connect two students when they know each other, we can also assign
weights to the edges to represent how often they interact with each other.</p>
<p>The <a href="https://igraph.org/"><code>igraph</code> package</a> provides functions to represent and
analyze networks in several language, <a href="https://igraph.org/r/">including R</a>. In
the examples below, we will use the igraph package to demonstrate the concepts
described in this section.</p>
<div class="sourceCode" id="cb258"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r.igraph.org/">igraph</a></span><span class="op">)</span></span></code></pre></div>
<p>The <a href="https://igraph.org/r/doc/sample_gnm.html"><code>sample_gnm(n,m)</code> function</a>
generates a random network with <span class="math inline">\(n\)</span> nodes and <span class="math inline">\(m\)</span> edges between them. We will
use this function below to generate random networks of different types.</p>
<p>A <strong>cyclic network</strong> has at least one directed path that starts and ends in the
same node.</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">samp_g</span> <span class="op">&lt;-</span> <span class="fu">igraph</span><span class="fu">::</span><span class="fu"><a href="https://r.igraph.org/reference/sample_gnm.html">sample_gnm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">4</span>, m <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-83-1.png" width="672"></div>
<p>An <strong>acyclic network</strong> , on the other hand, does not have any cycle path.</p>
<div class="sourceCode" id="cb260"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">samp_g</span> <span class="op">&lt;-</span> <span class="fu">igraph</span><span class="fu">::</span><span class="fu"><a href="https://r.igraph.org/reference/sample_gnm.html">sample_gnm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, m <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-84-1.png" width="672"></div>
<p>The edges in a <strong>directed network</strong> point to one specific direction (but, edges
can point in both directions, which are equivalent to undirected edges). One
common example is a network representing cell metabolic process, where certain
proteins biochemically modify, e.g. phosphorylate, other proteins.</p>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">samp_g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r.igraph.org/reference/sample_gnm.html">sample_gnm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, m <span class="op">=</span> <span class="fl">7</span>, directed <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-85-1.png" width="672"></div>
<p>The edges in a <strong>indirect network</strong> do not have direction. Common examples
include social interaction network and gene correlation network.</p>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">samp_g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r.igraph.org/reference/sample_gnm.html">sample_gnm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, m <span class="op">=</span> <span class="fl">7</span>, directed <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-86-1.png" width="672"></div>
<div id="basic-network-analysis" class="section level3" number="7.5.1">
<h3>
<span class="header-section-number">7.5.1</span> Basic network analysis<a class="anchor" aria-label="anchor" href="#basic-network-analysis"><i class="fas fa-link"></i></a>
</h3>
<div id="shortest-path" class="section level4" number="7.5.1.1">
<h4>
<span class="header-section-number">7.5.1.1</span> Shortest path<a class="anchor" aria-label="anchor" href="#shortest-path"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>shortest path</strong> between two vertices is… yes, the shortest path you can go from one vertex to the other. There may be more than one shortest paths between two vertices.</p>
<p>In the following network, there are many ways to go from “Moon_Capital” to “Crystal_Corridor”, but there’s only one shortest path, which is “Moon_Capital” -&gt; “Gryphon’s_Nest” -&gt; “Crystal_Corridor”. On the other hand, when you want to go from “Moon_Capital” to “Icy_Turret”, there are two possible ways: one through “Gryphon’s_Nest”, one through “Agate_Trademart”.</p>
<div class="inline-figure"><img src="main_files/unnamed-chunk-87-1.png" width="672"></div>
<p>In <code>igraph</code>, this can be calculated using <code><a href="https://r.igraph.org/reference/distances.html">shortest_paths()</a></code>.</p>
<div class="sourceCode" id="cb263"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r.igraph.org/reference/distances.html">shortest_paths</a></span><span class="op">(</span><span class="va">samp_g</span>, from <span class="op">=</span> <span class="st">"Moon_Capital"</span>, to <span class="op">=</span> <span class="st">"Crystal_Corridor"</span><span class="op">)</span><span class="op">$</span><span class="va">vpath</span></span></code></pre></div>
<pre><code>## [[1]]
## + 3/5 vertices, named, from fb97f3e:
## [1] Moon_Capital     Gryphon's_Nest   Crystal_Corridor</code></pre>
<p>One thing to keep in mind is, when <strong>weights</strong> are assigned to edges and being considered, the shortest path may <em>not</em> be the path that goes through the least number of vertices. In this example, consider the weight assigned to the edge connecting “Moon_Capital” and “Gryphon’s_Nest” is substantially large. <font color="grey"><del>The Royal Priest warned you that Gryphons live at the top of the hill, and it’s too hard to climb.</del></font></p>
<p>Let’s color the edges according to their weights. Green means 1, blue means 2 while red means 3. Now, the shortest path from “Moon_Capital” to “Crystal_Corridor” becomes “Moon_Capital” -&gt; “Agate_Trademart” -&gt; “Icy_Turret” -&gt; “Crystal_Corridor”.</p>
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">names</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Moon_Capital"</span>, <span class="st">"Icy_Turret"</span>, <span class="st">"Crystal_Corridor"</span>, <span class="st">"Gryphon's_Nest"</span>, <span class="st">"Agate_Trademart"</span><span class="op">)</span></span>
<span><span class="va">samp_g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r.igraph.org/reference/sample_gnm.html">sample_gnm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, m <span class="op">=</span> <span class="fl">7</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>name <span class="op">=</span> <span class="va">names</span>, color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/edge_attr.html">edge_attr</a></span><span class="op">(</span><span class="va">samp_g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"deepskyblue"</span>, <span class="st">"salmon"</span>, <span class="st">"deepskyblue"</span>, <span class="st">"deepskyblue"</span>, <span class="st">"palegreen3"</span>, <span class="st">"palegreen3"</span>, <span class="st">"salmon"</span><span class="op">)</span>,</span>
<span>  weights <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samp_g</span>,</span>
<span>  vertex.label.cex <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  vertex.label.dist <span class="op">=</span> <span class="fl">3</span>, edge.width <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-89-1.png" width="672"></div>
<p>We can conveniently find the shortest path with weights assigned!</p>
<div class="sourceCode" id="cb266"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r.igraph.org/reference/distances.html">shortest_paths</a></span><span class="op">(</span><span class="va">samp_g</span>,</span>
<span>  from <span class="op">=</span> <span class="st">"Moon_Capital"</span>, to <span class="op">=</span> <span class="st">"Crystal_Corridor"</span>,</span>
<span>  weights <span class="op">=</span> <span class="fu"><a href="https://r.igraph.org/reference/edge_attr.html">edge_attr</a></span><span class="op">(</span><span class="va">samp_g</span>, <span class="st">"weights"</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">vpath</span></span></code></pre></div>
<pre><code>## [[1]]
## + 4/5 vertices, named, from 4af1101:
## [1] Moon_Capital     Agate_Trademart  Icy_Turret       Crystal_Corridor</code></pre>
</div>
<div id="vertex-centrality" class="section level4" number="7.5.1.2">
<h4>
<span class="header-section-number">7.5.1.2</span> Vertex centrality<a class="anchor" aria-label="anchor" href="#vertex-centrality"><i class="fas fa-link"></i></a>
</h4>
<p>The <strong>degree of a vertex</strong> is the number of edges connected to it. In <code>igraph</code>, this can be calculated using <code><a href="https://r.igraph.org/reference/degree.html">degree()</a></code>.</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://r.igraph.org/reference/graph_from_data_frame.html">graph_from_data_frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  <span class="st">"from"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"A"</span>, <span class="st">"A"</span>, <span class="st">"A"</span>, <span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>, <span class="st">"A"</span>, <span class="st">"G"</span>, <span class="st">"H"</span>, <span class="st">"H"</span>, <span class="st">"H"</span>, <span class="st">"H"</span>, <span class="st">"H"</span>, <span class="st">"M"</span>, <span class="st">"I"</span>, <span class="st">"G"</span>, <span class="st">"N"</span>, <span class="st">"N"</span><span class="op">)</span>,</span>
<span>  <span class="st">"to"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"B"</span>, <span class="st">"C"</span>, <span class="st">"D"</span>, <span class="st">"E"</span>, <span class="st">"F"</span>, <span class="st">"D"</span>, <span class="st">"E"</span>, <span class="st">"G"</span>, <span class="st">"H"</span>, <span class="st">"I"</span>, <span class="st">"J"</span>, <span class="st">"K"</span>, <span class="st">"L"</span>, <span class="st">"M"</span>, <span class="st">"K"</span>, <span class="st">"J"</span>, <span class="st">"N"</span>, <span class="st">"O"</span>, <span class="st">"P"</span><span class="op">)</span></span>
<span><span class="op">)</span>, directed <span class="op">=</span> <span class="cn">F</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>name <span class="op">=</span> <span class="fu"><a href="https://r.igraph.org/reference/vertex_attr.html">vertex_attr</a></span><span class="op">(</span><span class="va">g</span>, <span class="st">"name"</span><span class="op">)</span>, color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"slategray1"</span>, <span class="fu"><a href="https://r.igraph.org/reference/gorder.html">gorder</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/unnamed-chunk-91-1.png" width="672"></div>
<div class="sourceCode" id="cb269"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r.igraph.org/reference/degree.html">degree</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span></span></code></pre></div>
<pre><code>## A B C G H M I N D E F J K L O P 
## 6 2 2 3 6 2 2 3 2 2 1 2 2 1 1 1</code></pre>
<p>The <strong>centrality</strong> of a vertex indicates how important it is in a network. For instance, after seeing a social interaction network, one question we can ask is “which person has the most influential power in this community?”. There are many different types of centrality, here we will only go through the basics.</p>
<p>To some extent, the degree can be used to evaluate the importance of a vertex. When a vertex is connected to a lot of other vertices, it naturally appears to be more important and has more ability to pass down information to other vertices. Assume you just opened a new on-line shop and you want to attract new customers as many as possible, you start by reaching out to the person you know has the largest number of friends.</p>
<p>But, sometimes, people with the largest number of friends may not necessarily be the one who can “spread the word” to the whole community the most efficiently. In the example above, although A and H have a lot of connections, in fact, it seems like if we pass an information to G, the whole community will be influenced the most quickly.</p>
<p>This leads us to <strong>closeness centrality</strong>, which is the sum of the length of the shortest paths between a node and all the other nodes in the graph. Although A and H have a lot of friends, it takes too long to reach the other side of the graph. When we calculating the closeness centrality using <code><a href="https://r.igraph.org/reference/closeness.html">closeness()</a></code> function to calculate closeness centrality.</p>
<div class="sourceCode" id="cb271"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r.igraph.org/reference/closeness.html">closeness</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span></span></code></pre></div>
<pre><code>##          A          B          C          G          H          M          I 
## 0.03225806 0.02272727 0.02272727 0.03703704 0.03225806 0.02272727 0.02272727 
##          N          D          E          F          J          K          L 
## 0.02702703 0.02272727 0.02272727 0.02222222 0.02272727 0.02272727 0.02222222 
##          O          P 
## 0.01960784 0.01960784</code></pre>
<p><strong>Betweenness centrality</strong> is the number of shortest paths that pass through the vertex. In this example, G is the also the one with the highest betweenness centrality.</p>
<div class="sourceCode" id="cb273"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://r.igraph.org/reference/betweenness.html">betweenness</a></span><span class="op">(</span><span class="va">g</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  A  B  C  G  H  M  I  N  D  E  F  J  K  L  O  P 
## 58  0  0 72 58  0  0 27  0  0  0  0  0  0  0  0</code></pre>
</div>
</div>
<div id="create-your-own" class="section level3" number="7.5.2">
<h3>
<span class="header-section-number">7.5.2</span> Create your own<a class="anchor" aria-label="anchor" href="#create-your-own"><i class="fas fa-link"></i></a>
</h3>
<p>Check the network visualization section to see a more detailed illustration about how to create your own network from scratch, and how to customize it!</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="data-wrangling.html"><span class="header-section-number">6</span> Data Wrangling</a></div>
<div class="next"><a href="data-visualization.html"><span class="header-section-number">8</span> Data Visualization</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-science"><span class="header-section-number">7</span> Data Science</a></li>
<li>
<a class="nav-link" href="#data-modeling"><span class="header-section-number">7.1</span> Data Modeling</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-worked-modeling-example"><span class="header-section-number">7.1.1</span> A Worked Modeling Example</a></li>
<li><a class="nav-link" href="#data-summarization"><span class="header-section-number">7.1.2</span> Data Summarization</a></li>
<li><a class="nav-link" href="#linear-models"><span class="header-section-number">7.1.3</span> Linear Models</a></li>
<li><a class="nav-link" href="#flavors-of-linear-models"><span class="header-section-number">7.1.4</span> Flavors of Linear Models</a></li>
<li><a class="nav-link" href="#assessing-model-accuracy-."><span class="header-section-number">7.1.5</span> Assessing Model Accuracy .</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#statistical-distributions"><span class="header-section-number">7.2</span> Statistical Distributions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#random-variables"><span class="header-section-number">7.2.1</span> Random Variables</a></li>
<li><a class="nav-link" href="#statistical-distribution-basics"><span class="header-section-number">7.2.2</span> Statistical Distribution Basics</a></li>
<li><a class="nav-link" href="#distributions-in-r"><span class="header-section-number">7.2.3</span> Distributions in R</a></li>
<li><a class="nav-link" href="#discrete-distributions"><span class="header-section-number">7.2.4</span> Discrete Distributions</a></li>
<li><a class="nav-link" href="#continuous-distributions"><span class="header-section-number">7.2.5</span> Continuous Distributions</a></li>
<li><a class="nav-link" href="#empirical-distributions"><span class="header-section-number">7.2.6</span> Empirical Distributions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#statistical-tests"><span class="header-section-number">7.3</span> Statistical Tests</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#what-is-a-statistical-test"><span class="header-section-number">7.3.1</span> What is a statistical test</a></li>
<li><a class="nav-link" href="#common-statistical-tests"><span class="header-section-number">7.3.2</span> Common Statistical Tests</a></li>
<li><a class="nav-link" href="#choosing-a-test"><span class="header-section-number">7.3.3</span> Choosing a Test</a></li>
<li><a class="nav-link" href="#p-values"><span class="header-section-number">7.3.4</span> P-values</a></li>
<li><a class="nav-link" href="#multiple-hypothesis-testing-."><span class="header-section-number">7.3.5</span> Multiple Hypothesis Testing .</a></li>
<li><a class="nav-link" href="#statistical-power"><span class="header-section-number">7.3.6</span> Statistical power</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#exploratory-data-analysis"><span class="header-section-number">7.4</span> Exploratory Data Analysis</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#principal-component-analysis"><span class="header-section-number">7.4.1</span> Principal Component Analysis</a></li>
<li><a class="nav-link" href="#cluster-analysis"><span class="header-section-number">7.4.2</span> Cluster Analysis</a></li>
<li><a class="nav-link" href="#k-means-."><span class="header-section-number">7.4.3</span> k-means .</a></li>
<li><a class="nav-link" href="#others"><span class="header-section-number">7.4.4</span> Others</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#network-analysis"><span class="header-section-number">7.5</span> Network Analysis</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#basic-network-analysis"><span class="header-section-number">7.5.1</span> Basic network analysis</a></li>
<li><a class="nav-link" href="#create-your-own"><span class="header-section-number">7.5.2</span> Create your own</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>BF591 - R for Biological Sciences</strong>" was written by . </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
